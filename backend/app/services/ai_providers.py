import openai
import anthropic
from google import genai
from typing import Dict, List, Any, AsyncGenerator, Union
import asyncio
import logging
import json
import os
import time
import base64
import httpx
import warnings
from .web_search_service import WebSearchService

# ç¦ç”¨ Pydantic åºåˆ—åŒ–è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning, module='pydantic')

logger = logging.getLogger(__name__)

class AIProviderService:
    def __init__(self):
        # è®¾ç½®ä¸åŒæ“ä½œçš„è¶…æ—¶æ—¶é—´
        self.default_timeout = 60  # é»˜è®¤60ç§’è¶…æ—¶
        self.responses_api_timeout = 180  # Responses API ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´
        self.config_timeout = 30  # é…ç½®åŠ è½½è¶…æ—¶
        self.max_retries = 2  # æœ€å¤§é‡è¯•æ¬¡æ•°
        self._models_config = None
        self.web_search_service = WebSearchService()  # åˆå§‹åŒ–æœç´¢æœåŠ¡
        
    def _get_message_attr(self, msg: Union[Dict[str, Any], Any], attr: str) -> str:
        """å®‰å…¨åœ°è·å–æ¶ˆæ¯å±æ€§ï¼Œæ”¯æŒå­—å…¸å’ŒPydanticå¯¹è±¡"""
        if isinstance(msg, dict):
            return msg.get(attr, "")
        else:
            # Pydanticå¯¹è±¡ï¼Œä½¿ç”¨å±æ€§è®¿é—®
            return getattr(msg, attr, "")
    
    def _convert_message_to_openai_format(self, msg: Union[Dict[str, Any], Any]) -> Dict[str, Any]:
        """å°†æ¶ˆæ¯è½¬æ¢ä¸ºOpenAI APIæ ¼å¼ï¼Œæ”¯æŒå›¾ç‰‡å’Œæ–‡ä»¶é™„ä»¶"""
        role = self._get_message_attr(msg, "role")
        content = self._get_message_attr(msg, "content")
        
        # è·å–å›¾ç‰‡æ•°æ®
        images = None
        if isinstance(msg, dict):
            images = msg.get("images")
        else:
            images = getattr(msg, "images", None)
        
        # è·å–æ–‡ä»¶æ•°æ®
        files = None
        if isinstance(msg, dict):
            files = msg.get("files")
        else:
            files = getattr(msg, "files", None)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤šåª’ä½“å†…å®¹
        has_multimedia = (images and len(images) > 0) or (files and len(files) > 0)
        
        # å¦‚æœæ²¡æœ‰å¤šåª’ä½“å†…å®¹ï¼Œä½¿ç”¨ä¼ ç»Ÿæ ¼å¼
        if not has_multimedia:
            return {"role": role, "content": content}
        
        # æ„é€ æ”¯æŒå¤šåª’ä½“çš„æ¶ˆæ¯æ ¼å¼
        content_parts = []
        
        # æ·»åŠ æ–‡æœ¬å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
        if content and content.strip():
            content_parts.append({"type": "text", "text": content})
        
        # æ·»åŠ å›¾ç‰‡å†…å®¹
        if images:
            for image in images:
                if isinstance(image, dict):
                    image_data = image.get("data")
                    mime_type = image.get("mime_type", "image/jpeg")
                else:
                    image_data = getattr(image, "data", "")
                    mime_type = getattr(image, "mime_type", "image/jpeg")
                
                if image_data:
                    content_parts.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{mime_type};base64,{image_data}"
                        }
                    })
        
        # æ·»åŠ æ–‡ä»¶å†…å®¹ (ä½¿ç”¨input_fileæ ¼å¼)
        if files:
            for file in files:
                if isinstance(file, dict):
                    file_id = file.get("openai_file_id")
                    filename = file.get("filename")
                    process_mode = file.get("process_mode", "direct")
                else:
                    file_id = getattr(file, "openai_file_id", "")
                    filename = getattr(file, "filename", "")
                    process_mode = getattr(file, "process_mode", "direct")
                
                if file_id:
                    # æ ¹æ®å¤„ç†æ¨¡å¼å†³å®šå¦‚ä½•å¤„ç†æ–‡ä»¶
                    if process_mode == "direct":
                        # ç›´è¯»æ¨¡å¼ï¼šä½¿ç”¨ input_file
                        content_parts.append({
                            "type": "input_file",
                            "file_id": file_id
                        })
                    # Code Interpreter å’Œ File Search æ¨¡å¼çš„æ–‡ä»¶ä¼šåœ¨å·¥å…·é…ç½®ä¸­å¤„ç†
        
        return {
            "role": role,
            "content": content_parts
        }
    
    def _prepare_tools_config(self, messages: List[Union[Dict[str, Any], Any]], tools: List[Dict[str, Any]] = None, provider: str = "openai") -> Dict[str, Any]:
        """å‡†å¤‡å·¥å…·é…ç½®ï¼ŒåŸºäºæ¶ˆæ¯ä¸­çš„æ–‡ä»¶ç±»å‹å’Œæä¾›å•†"""
        if provider == "anthropic":
            return self._prepare_anthropic_tools_config(messages, tools)
        else:
            return self._prepare_openai_tools_config(messages, tools)

    def _prepare_openai_tools_config(self, messages: List[Union[Dict[str, Any], Any]], tools: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """å‡†å¤‡OpenAIå·¥å…·é…ç½®"""
        tools_config = {"tools": []}

        # æ”¶é›†æ‰€æœ‰éœ€è¦çš„å·¥å…·
        need_code_interpreter = False
        need_file_search = False
        vector_stores = set()

        for msg in messages:
            # è·å–æ–‡ä»¶æ•°æ®
            files = None
            if isinstance(msg, dict):
                files = msg.get("files")
            else:
                files = getattr(msg, "files", None)

            if files:
                for file in files:
                    if isinstance(file, dict):
                        process_mode = file.get("process_mode", "direct")
                        vector_store_id = file.get("vector_store_id")
                    else:
                        process_mode = getattr(file, "process_mode", "direct")
                        vector_store_id = getattr(file, "vector_store_id", None)

                    if process_mode == "code_interpreter":
                        need_code_interpreter = True
                    elif process_mode == "file_search" and vector_store_id:
                        need_file_search = True
                        vector_stores.add(vector_store_id)

        # æ·»åŠ éœ€è¦çš„å·¥å…·
        if need_code_interpreter:
            tools_config["tools"].append({
                "type": "code_interpreter",
                "container": {"type": "auto"}
            })

        if need_file_search and vector_stores:
            tools_config["tools"].append({
                "type": "file_search",
                "vector_store_ids": list(vector_stores)
            })

        # æ·»åŠ å‰ç«¯ä¼ æ¥çš„å·¥å…·é…ç½®
        if tools:
            for tool_config in tools:
                if tool_config.get("type") in ["web_search", "web_search_preview"]:
                    web_search_tool = self.web_search_service.build_web_search_tool_config(tool_config)
                    tools_config["tools"].append(web_search_tool)
                elif tool_config.get("type") == "image_generation":
                    image_gen_tool = self._build_image_generation_tool_config(tool_config)
                    tools_config["tools"].append(image_gen_tool)
                elif tool_config.get("type") == "function":
                    function_tool = self._build_function_calling_tool_config(tool_config)
                    tools_config["tools"].append(function_tool)
                elif tool_config.get("type") in ["mcp_server", "mcp"]:
                    # OpenAIä½¿ç”¨Responses APIçš„MCPæ ¼å¼
                    mcp_tool = self._build_openai_mcp_tool_config(tool_config)
                    tools_config["tools"].append(mcp_tool)

        return tools_config

    def _prepare_anthropic_tools_config(self, messages: List[Union[Dict[str, Any], Any]], tools: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """å‡†å¤‡Anthropicå·¥å…·é…ç½®"""
        tools_config = {"tools": [], "mcp_servers": []}

        # Anthropicç›®å‰ä¸»è¦æ”¯æŒfunction callingå’ŒMCP
        if tools:
            for tool_config in tools:
                if tool_config.get("type") == "function":
                    # Anthropicçš„function callingæ ¼å¼
                    function_tool = {
                        "name": tool_config.get("name"),
                        "description": tool_config.get("description", ""),
                        "input_schema": tool_config.get("parameters", {})
                    }
                    tools_config["tools"].append(function_tool)
                elif tool_config.get("type") in ["mcp_server", "mcp"]:
                    # Anthropicä½¿ç”¨ä¸“é—¨çš„mcp_serverså‚æ•°
                    mcp_server = self._build_anthropic_mcp_server_config(tool_config)
                    tools_config["mcp_servers"].append(mcp_server)

        return tools_config
    
    def _build_image_generation_tool_config(self, tool_config: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºå›¾ç‰‡ç”Ÿæˆå·¥å…·é…ç½®"""
        config = {
            "type": "image_generation"
        }
        
        # æ·»åŠ å¯é€‰çš„å›¾ç‰‡ç”Ÿæˆå‚æ•°
        if "size" in tool_config:
            config["size"] = tool_config["size"]
        
        if "quality" in tool_config:
            config["quality"] = tool_config["quality"]
        
        if "format" in tool_config:
            config["format"] = tool_config["format"]
        
        if "compression" in tool_config:
            config["compression"] = tool_config["compression"]
        
        if "background" in tool_config:
            config["background"] = tool_config["background"]
        
        if "input_fidelity" in tool_config:
            config["input_fidelity"] = tool_config["input_fidelity"]
        
        if "input_image" in tool_config:
            config["input_image"] = tool_config["input_image"]
        
        if "input_image_mask" in tool_config:
            config["input_image_mask"] = tool_config["input_image_mask"]
        
        if "partial_images" in tool_config:
            config["partial_images"] = tool_config["partial_images"]
        
        # é»˜è®¤è®¾ç½®å®¡æ ¸çº§åˆ«ä¸ºlowï¼ˆå¦‚ç”¨æˆ·è¦æ±‚ï¼‰
        config["moderation"] = tool_config.get("moderation", "low")
        
        return config

    def _build_function_calling_tool_config(self, tool_config: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»º Function Calling å·¥å…·é…ç½®"""
        config = {
            "type": "function",
            "function": {
                "name": tool_config.get("name"),
                "description": tool_config.get("description", ""),
                "parameters": tool_config.get("parameters", {})
            }
        }

        # æ·»åŠ ä¸¥æ ¼æ¨¡å¼æ”¯æŒ
        if tool_config.get("strict"):
            config["function"]["strict"] = True

        return config

    def _build_openai_mcp_tool_config(self, tool_config: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºOpenAI MCPå·¥å…·é…ç½®ï¼ˆç¬¦åˆResponses APIæ ¼å¼ï¼‰"""
        # æ”¯æŒurlæˆ–server_urlå­—æ®µ
        server_url = tool_config.get("server_url") or tool_config.get("url")

        # éªŒè¯æœåŠ¡å™¨URLï¼ˆå¦‚æœæä¾›äº†URLï¼‰
        if server_url and not self._validate_mcp_server_url(server_url, "openai"):
            logger.error(f"OpenAI MCPæœåŠ¡å™¨URLéªŒè¯å¤±è´¥: {server_url}")

        config = {
            "type": "mcp",
            "server_label": tool_config.get("server_name", tool_config.get("server_label", tool_config.get("name"))),
            "server_url": server_url,
        }

        # æ·»åŠ å¯é€‰å­—æ®µ
        if "server_description" in tool_config:
            config["server_description"] = tool_config["server_description"]
        elif "description" in tool_config:
            config["server_description"] = tool_config["description"]

        # æ”¯æŒå†…ç½®è¿æ¥å™¨ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
        if "connector_id" in tool_config:
            config["connector_id"] = tool_config["connector_id"]
            # è¿æ¥å™¨ä¸éœ€è¦server_url
            if "server_url" in config:
                del config["server_url"]

        # æˆæƒé…ç½®
        if "authorization" in tool_config:
            config["authorization"] = tool_config["authorization"]

        # å®¡æ‰¹è¦æ±‚é…ç½®ï¼ˆæ”¯æŒç»†ç²’åº¦æ§åˆ¶ï¼‰
        if "require_approval" in tool_config:
            require_approval = tool_config["require_approval"]
            if isinstance(require_approval, dict):
                # æ”¯æŒå¯¹è±¡æ ¼å¼: {"never": {"tool_names": ["safe_tool"]}}
                config["require_approval"] = require_approval
            else:
                # æ”¯æŒå­—ç¬¦ä¸²æ ¼å¼: "always", "never"
                config["require_approval"] = require_approval
        else:
            # é»˜è®¤æ€»æ˜¯éœ€è¦å®¡æ‰¹ï¼ˆå®‰å…¨è€ƒè™‘ï¼‰
            config["require_approval"] = "always"

        # å…è®¸çš„å·¥å…·åˆ—è¡¨
        if "allowed_tools" in tool_config:
            config["allowed_tools"] = tool_config["allowed_tools"]

        return config

    def _handle_mcp_approval_message(self, msg: Union[Dict[str, Any], Any]) -> Dict[str, Any]:
        """å¤„ç†MCPå®¡æ‰¹å“åº”æ¶ˆæ¯ï¼ˆOpenAIæ ¼å¼ï¼‰"""
        if isinstance(msg, dict):
            approval_data = {
                "type": "mcp_approval_response",
                "approve": msg.get("approve", True),
                "approval_request_id": msg.get("approval_request_id")
            }
        else:
            approval_data = {
                "type": "mcp_approval_response",
                "approve": getattr(msg, "approve", True),
                "approval_request_id": getattr(msg, "approval_request_id", "")
            }

        return {
            "role": "user",
            "content": [{"type": "mcp_approval_response", **approval_data}]
        }

    def _validate_mcp_server_url(self, url: str, provider: str = "openai") -> bool:
        """éªŒè¯MCPæœåŠ¡å™¨URLæ˜¯å¦ç¬¦åˆå®‰å…¨è¦æ±‚"""
        if not url:
            return False

        # Anthropicè¦æ±‚ä½¿ç”¨HTTPS
        if provider == "anthropic" and not url.startswith("https://"):
            logger.warning(f"Anthropic MCPæœåŠ¡å™¨URLå¿…é¡»ä½¿ç”¨HTTPS: {url}")
            return False

        # OpenAIæ¨èä½¿ç”¨HTTPS
        if provider == "openai" and not url.startswith(("https://", "http://localhost", "http://127.0.0.1")):
            logger.warning(f"OpenAI MCPæœåŠ¡å™¨URLå»ºè®®ä½¿ç”¨HTTPSï¼ˆé™¤éæ˜¯æœ¬åœ°æµ‹è¯•ï¼‰: {url}")
            return False

        return True

    def _build_anthropic_mcp_server_config(self, tool_config: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºAnthropic MCPæœåŠ¡å™¨é…ç½®ï¼ˆç¬¦åˆMessages APIæ ¼å¼ï¼‰"""
        server_url = tool_config.get("server_url", tool_config.get("url"))

        # éªŒè¯æœåŠ¡å™¨URLï¼ˆAnthropicè¦æ±‚HTTPSï¼‰
        if server_url and not self._validate_mcp_server_url(server_url, "anthropic"):
            logger.error(f"Anthropic MCPæœåŠ¡å™¨URLéªŒè¯å¤±è´¥: {server_url}")

        config = {
            "type": "url",
            "name": tool_config.get("server_name", tool_config.get("name")),
            "url": server_url
        }

        # æˆæƒä»¤ç‰Œ
        if "authorization" in tool_config:
            config["authorization_token"] = tool_config["authorization"]
        elif "authorization_token" in tool_config:
            config["authorization_token"] = tool_config["authorization_token"]

        # å·¥å…·é…ç½®
        tool_configuration = {}

        # å¯ç”¨çŠ¶æ€
        if "enabled" in tool_config:
            tool_configuration["enabled"] = tool_config["enabled"]
        else:
            tool_configuration["enabled"] = True

        # å…è®¸çš„å·¥å…·åˆ—è¡¨
        if "allowed_tools" in tool_config and tool_config["allowed_tools"]:
            tool_configuration["allowed_tools"] = tool_config["allowed_tools"]

        if tool_configuration:
            config["tool_configuration"] = tool_configuration

        return config

    def _find_previous_image_generation(self, messages: List[Union[Dict[str, Any], Any]]) -> str:
        """æŸ¥æ‰¾ä¹‹å‰çš„å›¾ç‰‡ç”Ÿæˆç»“æœçš„IDï¼Œç”¨äºå¤šè½®å›¾åƒç”Ÿæˆ"""
        # ä»æœ€è¿‘çš„æ¶ˆæ¯å¼€å§‹å‘åæŸ¥æ‰¾
        for msg in reversed(messages):
            role = self._get_message_attr(msg, "role")
            if role == "assistant":
                # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡ç”Ÿæˆç»“æœ
                image_generations = None
                if isinstance(msg, dict):
                    image_generations = msg.get("image_generations")
                else:
                    image_generations = getattr(msg, "image_generations", None)
                
                if image_generations and len(image_generations) > 0:
                    # è¿”å›æœ€è¿‘çš„å›¾ç‰‡ç”ŸæˆID
                    return image_generations[-1].get("id", "")
        
        return ""
    
    async def _handle_web_search_fallback(
        self, 
        completion_params: Dict[str, Any], 
        tools: List[Dict[str, Any]], 
        messages: List[Union[Dict[str, str], Any]]
    ) -> Dict[str, Any]:
        """
        å¤„ç†Web Searchçš„æ—§ç‰ˆå›é€€é€»è¾‘
        ä½¿ç”¨æ—§ç‰ˆ web_search_preview å‚æ•°æ ¼å¼
        """
        # æŸ¥æ‰¾æœç´¢å·¥å…·é…ç½®
        search_tool = None
        for tool in tools:
            if tool.get("type") in ["web_search", "web_search_preview"]:
                search_tool = tool
                break
        
        if search_tool:
            # æ—§ç‰ˆå®ç°ï¼šæ·»åŠ  web_search_preview å‚æ•°
            completion_params["web_search_preview"] = True
            
            # æ·»åŠ ç”¨æˆ·ä½ç½®ä¿¡æ¯ï¼ˆå¦‚æœæä¾›ï¼‰
            if search_tool.get("user_location"):
                completion_params["user_location"] = search_tool["user_location"]
        
        return completion_params
        
    async def _load_models_config(self) -> Dict[str, Any]:
        """åŠ è½½æ¨¡å‹é…ç½®"""
        if self._models_config is None:
            config_url = "https://raw.githubusercontent.com/marvinli001/MineChatWeb/main/models-config.json"
            async with httpx.AsyncClient(timeout=self.config_timeout) as client:
                response = await client.get(config_url)
                response.raise_for_status()
                self._models_config = response.json()
                logger.info("æˆåŠŸä»è¿œç¨‹åŠ è½½æ¨¡å‹é…ç½®")
        return self._models_config
        
    async def get_completion(
        self,
        provider: str,
        model: str,
        messages: List[Union[Dict[str, str], Any]],  # Support both dict and Pydantic objects
        api_key: str,
        stream: bool = False,
        thinking_mode: bool = False,
        reasoning_summaries: str = "auto",
        reasoning: str = "medium",
        tools: List[Dict[str, Any]] = None,
        use_native_search: bool = None,
        base_url: str = None
    ) -> Dict[str, Any]:
        """è·å–AIå®Œæˆå“åº”"""
        logger.info(f"å¼€å§‹è°ƒç”¨ {provider} API, æ¨¡å‹: {model}, æ€è€ƒæ¨¡å¼: {thinking_mode}")
        
        # ä½¿ç”¨é‡è¯•æœºåˆ¶
        last_exception = None
        for attempt in range(self.max_retries + 1):
            try:
                if provider == "openai":
                    # OpenAI æä¾›å•†ç°åœ¨åªä½¿ç”¨ Responses API
                    return await self._openai_responses_completion(model, messages, api_key, thinking_mode, reasoning_summaries, reasoning, tools, use_native_search)
                elif provider == "anthropic":
                    return await self._anthropic_completion(model, messages, api_key, thinking_mode, tools, stream)
                elif provider == "google":
                    return await self._google_completion(model, messages, api_key, stream, thinking_mode, reasoning_summaries, reasoning, tools, use_native_search)
                elif provider == "openai_compatible":
                    return await self._openai_compatible_completion(model, messages, api_key, stream, thinking_mode, reasoning_summaries, tools, use_native_search, base_url)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {provider}")
                    
            except asyncio.TimeoutError as e:
                last_exception = e
                logger.warning(f"{provider} APIè°ƒç”¨è¶…æ—¶ (å°è¯• {attempt + 1}/{self.max_retries + 1})")
                if attempt < self.max_retries:
                    await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    continue
                else:
                    logger.error(f"{provider} APIè°ƒç”¨åœ¨ {self.max_retries + 1} æ¬¡å°è¯•åä»ç„¶è¶…æ—¶")
                    raise Exception(f"{provider} APIè°ƒç”¨è¶…æ—¶ï¼Œå·²é‡è¯•{self.max_retries}æ¬¡ï¼Œè¯·ç¨åé‡è¯•")
            except Exception as e:
                last_exception = e
                # å¯¹äºæŸäº›é”™è¯¯ç±»å‹ï¼Œä¸è¿›è¡Œé‡è¯•
                if any(keyword in str(e).lower() for keyword in ['authentication', 'authorization', 'api key', 'invalid']):
                    logger.error(f"{provider} APIè°ƒç”¨å¤±è´¥ (è®¤è¯é”™è¯¯): {str(e)}")
                    raise
                elif attempt < self.max_retries:
                    logger.warning(f"{provider} APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries + 1}): {str(e)}")
                    await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    continue
                else:
                    logger.error(f"{provider} APIè°ƒç”¨åœ¨ {self.max_retries + 1} æ¬¡å°è¯•åä»ç„¶å¤±è´¥: {str(e)}")
                    raise
        
        # è¿™è¡Œä¸åº”è¯¥åˆ°è¾¾ï¼Œä½†ä¸ºäº†ç±»å‹å®‰å…¨
        if last_exception:
            raise last_exception

    def _is_thinking_model(self, model: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ€è€ƒæ¨¡å‹"""
        thinking_models = [
            'o1', 'o1-preview', 'o1-mini', 'o1-pro',
            'o3', 'o3-mini', 'o3-pro',
            'o4-mini', 'o4-mini-high'
        ]
        return model in thinking_models

    async def _is_openai_responses_api(self, model: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸º OpenAI Responses API æ¨¡å‹"""
        try:
            config = await self._load_models_config()  # æ·»åŠ  await
            openai_models = config.get('providers', {}).get('openai', {}).get('models', {})
            model_config = openai_models.get(model, {})
            return model_config.get('api_type') == 'responses'
        except Exception as e:
            logger.warning(f"æ— æ³•æ£€æŸ¥æ¨¡å‹APIç±»å‹: {e}")
            # å›é€€åˆ°ç¡¬ç¼–ç åˆ—è¡¨
            fallback_models = [
                'chatgpt-4o-latest',
                'gpt-4o-realtime-preview',
                'gpt-4o-realtime-preview-2024-10-01',
                'gpt-5', 'gpt-5-mini', 'gpt-5-nano', 'gpt-5-chat-latest',
                'gpt-4o', 'gpt-4o-mini',
                'gpt-4.1', 'gpt-4.1-mini', 'gpt-4.1-nano',
                'o1', 'o1-preview', 'o1-mini', 'o3', 'o3-mini', 'o4-mini'
            ]
            return model in fallback_models

    async def _supports_streaming(self, provider: str, model: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒæµå¼è¾“å‡º"""
        try:
            config = await self._load_models_config()  # æ·»åŠ  await
            provider_models = config.get('providers', {}).get(provider, {}).get('models', {})
            model_config = provider_models.get(model, {})
            return model_config.get('supports_streaming', False)
        except Exception as e:
            logger.warning(f"æ— æ³•æ£€æŸ¥æ¨¡å‹æµå¼æ”¯æŒ: {e}")
            # å¯¹äºOpenAIï¼Œé™¤äº†thinkingæ¨¡å‹å¤–ï¼Œé»˜è®¤æ”¯æŒæµå¼
            if provider == 'openai':
                thinking_models = ['o1', 'o1-preview', 'o1-mini', 'o3', 'o3-mini', 'o4-mini']
                return model not in thinking_models
            return False

    def _is_gpt5_model(self, model: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸º GPT-5 ç³»åˆ—æ¨¡å‹"""
        gpt5_models = ['gpt-5', 'gpt-5-mini', 'gpt-5-nano', 'gpt-5-chat-latest']
        return model in gpt5_models

    def _supports_thinking_mode(self, model: str) -> bool:
        """åˆ¤æ–­æ¨¡å‹æ˜¯å¦æ”¯æŒ thinking mode (é€šè¿‡ reasoning_effort å‚æ•°)"""
        return self._is_gpt5_model(model)

    def _convert_responses_to_chat_format(self, responses_result: Dict[str, Any]) -> Dict[str, Any]:
        """å°† Responses API æ ¼å¼è½¬æ¢ä¸ºæ ‡å‡† Chat Completions æ ¼å¼"""
        if "choices" in responses_result:
            # å·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼Œç›´æ¥è¿”å›
            return responses_result

        if "output" not in responses_result:
            # ä¸æ˜¯ Responses API æ ¼å¼ï¼Œç›´æ¥è¿”å›
            return responses_result

        # è½¬æ¢ Responses API æ ¼å¼
        output = responses_result.get("output", [])
        choices = []
        reasoning_content = ""
        image_generations = []
        function_calls = []
        custom_tool_calls = []
        mcp_list_tools = []
        mcp_calls = []
        mcp_approval_requests = []

        # æå–ä¸åŒç±»å‹çš„è¾“å‡ºå†…å®¹
        assistant_content = ""
        finish_reason = "stop"

        for item in output:
            # æå–æ¨ç†å†…å®¹
            if item.get("type") == "reasoning":
                summary_items = item.get("summary", [])
                for summary_item in summary_items:
                    if summary_item.get("type") == "summary_text":
                        reasoning_content = summary_item.get("text", "")
                        break

            # æå–å›¾ç‰‡ç”Ÿæˆç»“æœ
            elif item.get("type") == "image_generation_call":
                image_gen = {
                    "id": item.get("id"),
                    "type": "image_generation_call",
                    "status": item.get("status"),
                    "result": item.get("result"),
                    "revised_prompt": item.get("revised_prompt")
                }
                image_generations.append(image_gen)

            # æå–function callingç»“æœï¼ˆæ ¹æ®å®˜æ–¹æ–‡æ¡£æ ¼å¼ï¼‰
            elif item.get("type") == "function_call":
                function_call = {
                    "id": item.get("call_id", item.get("id")),  # ä½¿ç”¨call_idä½œä¸ºä¸»ID
                    "type": "function",
                    "function": {
                        "name": item.get("name"),
                        "arguments": item.get("arguments", "{}")
                    }
                }
                function_calls.append(function_call)
                finish_reason = "tool_calls"

            # æå–custom tool callingç»“æœ
            elif item.get("type") == "custom_tool_call":
                custom_tool_call = {
                    "id": item.get("id"),
                    "type": "custom_tool_call",
                    "name": item.get("name"),
                    "input": item.get("input", ""),
                    "call_id": item.get("call_id")
                }
                custom_tool_calls.append(custom_tool_call)
                finish_reason = "tool_calls"

            # æå–MCPå·¥å…·åˆ—è¡¨ï¼ˆæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼‰
            elif item.get("type") == "mcp_list_tools":
                mcp_list_tool = {
                    "id": item.get("id"),
                    "type": "mcp_list_tools",
                    "server_label": item.get("server_label"),
                    "tools": item.get("tools", [])
                }
                mcp_list_tools.append(mcp_list_tool)

            # æå–MCPè°ƒç”¨ç»“æœ
            elif item.get("type") == "mcp_call":
                mcp_call = {
                    "id": item.get("id"),
                    "type": "mcp_call",
                    "server_label": item.get("server_label"),
                    "name": item.get("name"),
                    "arguments": item.get("arguments"),
                    "output": item.get("output"),
                    "error": item.get("error"),
                    "approval_request_id": item.get("approval_request_id"),
                    "status": item.get("status", "completed"),
                    "execution_time": item.get("execution_time")
                }
                mcp_calls.append(mcp_call)

                # æ ¹æ®MCPè°ƒç”¨çŠ¶æ€è®¾ç½®finish_reason
                if item.get("error"):
                    finish_reason = "mcp_error"
                elif item.get("approval_request_id"):
                    finish_reason = "approval_required"
                else:
                    finish_reason = "mcp_tool_calls"

            # æå–MCPå®¡æ‰¹è¯·æ±‚
            elif item.get("type") == "mcp_approval_request":
                mcp_approval_request = {
                    "id": item.get("id"),
                    "type": "mcp_approval_request",
                    "server_label": item.get("server_label"),
                    "name": item.get("name"),
                    "arguments": item.get("arguments")
                }
                mcp_approval_requests.append(mcp_approval_request)
                finish_reason = "approval_required"

            # æå–åŠ©æ‰‹æ¶ˆæ¯å†…å®¹
            elif item.get("type") == "message" and item.get("role") == "assistant":
                message_content = item.get("content", [])

                # æå–æ–‡æœ¬å†…å®¹
                for content_item in message_content:
                    if content_item.get("type") == "output_text":
                        assistant_content = content_item.get("text", "")
                        break

        # æ„é€ é€‰æ‹©å¯¹è±¡
        choice = {
            "message": {
                "role": "assistant",
                "content": assistant_content
            },
            "finish_reason": finish_reason,
            "index": 0
        }

        # æ·»åŠ tool_callså¦‚æœæœ‰function calling
        if function_calls:
            choice["message"]["tool_calls"] = function_calls

        # æ·»åŠ custom tool callså¦‚æœæœ‰
        if custom_tool_calls:
            choice["message"]["custom_tool_calls"] = custom_tool_calls

        # å¦‚æœæœ‰æ¨ç†å†…å®¹ï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
        if reasoning_content:
            choice["message"]["reasoning"] = reasoning_content

        # å¦‚æœæœ‰å›¾ç‰‡ç”Ÿæˆç»“æœï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
        if image_generations:
            choice["message"]["image_generations"] = image_generations

        # å¦‚æœæœ‰MCPå·¥å…·åˆ—è¡¨ï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
        if mcp_list_tools:
            choice["message"]["mcp_list_tools"] = mcp_list_tools

        # å¦‚æœæœ‰MCPè°ƒç”¨ç»“æœï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
        if mcp_calls:
            choice["message"]["mcp_calls"] = mcp_calls

        # å¦‚æœæœ‰MCPå®¡æ‰¹è¯·æ±‚ï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
        if mcp_approval_requests:
            choice["message"]["mcp_approval_requests"] = mcp_approval_requests

        choices.append(choice)

        # å¦‚æœæ²¡æœ‰ä»»ä½•å†…å®¹ä½†æœ‰å›¾ç‰‡ç”Ÿæˆç»“æœï¼Œåˆ›å»ºä¸€ä¸ªç©ºæ¶ˆæ¯æ¥æ‰¿è½½å›¾ç‰‡
        if not choices and image_generations:
            choice = {
                "message": {
                    "role": "assistant",
                    "content": "",
                    "image_generations": image_generations
                },
                "finish_reason": "stop",
                "index": 0
            }
            choices.append(choice)

        # æ„é€ æ ‡å‡†æ ¼å¼å“åº”
        converted_result = {
            "id": responses_result.get("id", f"resp_{hash(str(output)) % 1000000}"),
            "choices": choices,
            "usage": responses_result.get("usage", {
                "prompt_tokens": 0,
                "completion_tokens": 0,
                "total_tokens": 0
            })
        }

        return converted_result

    async def _openai_responses_completion(
        self,
        model: str,
        messages: List[Union[Dict[str, str], Any]],  # Support both dict and Pydantic objects
        api_key: str,
        thinking_mode: bool = False,
        reasoning_summaries: str = "auto",
        reasoning: str = "medium",
        tools: List[Dict[str, Any]] = None,
        use_native_search: bool = None
    ) -> Dict[str, Any]:
        """OpenAI Responses API è°ƒç”¨"""
        try:
            # ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´ï¼Œå› ä¸º Responses API é€šå¸¸éœ€è¦æ›´å¤šæ—¶é—´
            timeout = self.responses_api_timeout if self._is_gpt5_model(model) or thinking_mode else self.default_timeout
            client = openai.AsyncOpenAI(
                api_key=api_key,
                timeout=timeout
            )
            
            logger.info(f"è°ƒç”¨OpenAI Responses APIæ¨¡å‹: {model}, æ€è€ƒæ¨¡å¼: {thinking_mode}")
            
            # å¯¹äº GPT-5 ç³»åˆ—æ¨¡å‹ï¼Œä½¿ç”¨ Responses API æ”¯æŒ thinking mode
            if self._is_gpt5_model(model) and thinking_mode:
                # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡æ¶ˆæ¯
                has_images = any(
                    (isinstance(msg, dict) and msg.get("images")) or
                    (hasattr(msg, "images") and getattr(msg, "images", None))
                    for msg in messages
                )
                
                if has_images:
                    # Responses API æ”¯æŒå›¾ç‰‡ï¼Œéœ€è¦ä½¿ç”¨æ–°çš„æ ¼å¼
                    logger.info(f"æ£€æµ‹åˆ°å›¾ç‰‡æ¶ˆæ¯ï¼Œä½¿ç”¨Responses APIçš„å¤šæ¨¡æ€è¾“å…¥æ ¼å¼")
                    
                    # è½¬æ¢æ¶ˆæ¯ä¸º Responses API æ ¼å¼
                    input_messages = []
                    instructions_text = ""
                    
                    for msg in messages:
                        role = self._get_message_attr(msg, "role")
                        content = self._get_message_attr(msg, "content")

                        if role == "system":
                            instructions_text = content
                        elif role == "mcp_approval_response":
                            # å¤„ç†MCPå®¡æ‰¹å“åº”ï¼ˆç‰¹æ®Šæ¶ˆæ¯ç±»å‹ï¼‰
                            if isinstance(msg, dict):
                                input_messages.append({
                                    "type": "mcp_approval_response",
                                    "approve": msg.get("approve", True),
                                    "approval_request_id": msg.get("approval_request_id")
                                })
                            else:
                                # å¯¹äºPydanticå¯¹è±¡
                                input_messages.append({
                                    "type": "mcp_approval_response",
                                    "approve": getattr(msg, "approve", True),
                                    "approval_request_id": getattr(msg, "approval_request_id", "")
                                })
                        else:
                            # è·å–å›¾ç‰‡å’Œæ–‡ä»¶æ•°æ®
                            images = None
                            files = None
                            if isinstance(msg, dict):
                                images = msg.get("images")
                                files = msg.get("files")
                            else:
                                images = getattr(msg, "images", None)
                                files = getattr(msg, "files", None)
                            
                            # æ„é€ å†…å®¹éƒ¨åˆ†æ•°ç»„
                            content_parts = []
                            
                            # æ·»åŠ æ–‡æœ¬å†…å®¹
                            if content and content.strip():
                                content_parts.append({"type": "input_text", "text": content})
                            
                            # æ·»åŠ å›¾ç‰‡å†…å®¹
                            if images and len(images) > 0:
                                for image in images:
                                    if isinstance(image, dict):
                                        image_data = image.get("data")
                                        mime_type = image.get("mime_type", "image/jpeg")
                                    else:
                                        image_data = getattr(image, "data", "")
                                        mime_type = getattr(image, "mime_type", "image/jpeg")
                                    
                                    if image_data:
                                        content_parts.append({
                                            "type": "input_image",
                                            "image_url": f"data:{mime_type};base64,{image_data}"
                                        })
                            
                            # æ·»åŠ æ–‡ä»¶å†…å®¹ï¼ˆä»…æ”¯æŒ direct æ¨¡å¼çš„ PDF æ–‡ä»¶ï¼‰
                            if files and len(files) > 0:
                                for file in files:
                                    if isinstance(file, dict):
                                        openai_file_id = file.get("openai_file_id")
                                        process_mode = file.get("process_mode", "direct")
                                    else:
                                        openai_file_id = getattr(file, "openai_file_id", None)
                                        process_mode = getattr(file, "process_mode", "direct")
                                    
                                    # åªæœ‰ direct æ¨¡å¼çš„æ–‡ä»¶æ‰æ·»åŠ åˆ° input_fileï¼ˆä»…æ”¯æŒ PDFï¼‰
                                    if openai_file_id and process_mode == "direct":
                                        content_parts.append({
                                            "type": "input_file",
                                            "file_id": openai_file_id
                                        })
                            
                            # å¦‚æœæ²¡æœ‰å†…å®¹éƒ¨åˆ†ï¼Œæ·»åŠ ç©ºæ–‡æœ¬
                            if not content_parts:
                                content_parts.append({"type": "input_text", "text": ""})
                            
                            input_messages.append({
                                "role": role,
                                "content": content_parts
                            })
                    
                    # å‡†å¤‡å·¥å…·é…ç½®
                    tools_config = self._prepare_tools_config(messages, tools)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡ç”Ÿæˆå·¥å…·å¹¶æŸ¥æ‰¾ä¹‹å‰çš„å›¾ç‰‡ç”Ÿæˆç»“æœ
                    previous_image_gen_id = ""
                    has_image_gen_tool = tools and any(tool.get("type") == "image_generation" for tool in tools)
                    if has_image_gen_tool:
                        previous_image_gen_id = self._find_previous_image_generation(messages)
                    
                    # ä½¿ç”¨ Responses API çš„å¤šæ¨¡æ€å‚æ•°ç»“æ„
                    # å°†å‰ç«¯çš„ 'instant' æ˜ å°„ä¸º OpenAI API çš„ 'minimal'
                    effort_value = "minimal" if reasoning == "instant" else reasoning
                    completion_params = {
                        "model": model,
                        "input": input_messages,
                        "reasoning": {
                            "effort": effort_value,
                            "summary": reasoning_summaries if reasoning_summaries != "auto" else "auto"
                        }
                    }
                    
                    # å¦‚æœæœ‰ä¹‹å‰çš„å›¾ç‰‡ç”Ÿæˆç»“æœï¼Œæ·»åŠ åˆ°è¯·æ±‚ä¸­ï¼ˆç”¨äºå¤šè½®å›¾åƒç”Ÿæˆï¼‰
                    if previous_image_gen_id:
                        completion_params["previous_response_id"] = previous_image_gen_id
                        logger.info(f"ä½¿ç”¨previous_response_idè¿›è¡Œå¤šè½®å›¾åƒç”Ÿæˆ: {previous_image_gen_id}")
                    
                    # æ·»åŠ å·¥å…·é…ç½®
                    if tools_config["tools"]:
                        completion_params.update(tools_config)
                        # å¦‚æœæœ‰å·¥å…·ä¸”æ˜¯å¿…éœ€çš„ï¼Œè®¾ç½® tool_choice
                        need_code_interpreter = any(tool.get("type") == "code_interpreter" for tool in tools_config["tools"])
                        if need_code_interpreter:
                            completion_params["tool_choice"] = "required"
                    
                    # æ·»åŠ  instructions å¦‚æœæœ‰ system æ¶ˆæ¯
                    if instructions_text:
                        completion_params["instructions"] = instructions_text
                    
                    # GPT-5 ç³»åˆ—æ¨¡å‹ä½¿ç”¨ max_output_tokens
                    completion_params["max_output_tokens"] = 4000
                    
                    # æ‰“å°å®é™…å‘é€çš„ JSON
                    logger.info(f"ğŸ“¤ å‘é€ç»™ OpenAI Responses API çš„å®Œæ•´è¯·æ±‚: {json.dumps(completion_params, ensure_ascii=False, indent=2)}")
                    
                    response = await asyncio.wait_for(
                        client.responses.create(**completion_params),
                        timeout=timeout
                    )
                    
                    result = response.model_dump()
                    logger.info(f"OpenAI Responses APIè°ƒç”¨æˆåŠŸï¼ˆå¤šæ¨¡æ€æ”¯æŒï¼‰")
                    return self._convert_responses_to_chat_format(result)
                
                # è½¬æ¢æ¶ˆæ¯æ ¼å¼ä¸º Responses API æ‰€éœ€çš„ input æ ¼å¼
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ï¼Œå¦‚æœæœ‰åˆ™ä½¿ç”¨ç»“æ„åŒ–è¾“å…¥æ ¼å¼
                has_files = any(
                    (isinstance(msg, dict) and msg.get("files")) or
                    (hasattr(msg, "files") and getattr(msg, "files", None))
                    for msg in messages
                )
                
                instructions_text = ""
                
                if has_files:
                    # ä½¿ç”¨ç»“æ„åŒ–è¾“å…¥æ ¼å¼æ”¯æŒæ–‡ä»¶
                    input_messages = []
                    
                    for msg in messages:
                        role = self._get_message_attr(msg, "role")
                        content = self._get_message_attr(msg, "content")
                        
                        if role == "system":
                            instructions_text = content
                        else:
                            # è·å–æ–‡ä»¶æ•°æ®
                            files = None
                            if isinstance(msg, dict):
                                files = msg.get("files")
                            else:
                                files = getattr(msg, "files", None)
                            
                            # æ„é€ å†…å®¹éƒ¨åˆ†æ•°ç»„
                            content_parts = []
                            
                            # æ·»åŠ æ–‡æœ¬å†…å®¹
                            if content and content.strip():
                                content_parts.append({"type": "input_text", "text": content})
                            
                            # æ·»åŠ æ–‡ä»¶å†…å®¹ï¼ˆä»…æ”¯æŒ direct æ¨¡å¼çš„ PDF æ–‡ä»¶ï¼‰
                            if files and len(files) > 0:
                                for file in files:
                                    if isinstance(file, dict):
                                        openai_file_id = file.get("openai_file_id")
                                        process_mode = file.get("process_mode", "direct")
                                    else:
                                        openai_file_id = getattr(file, "openai_file_id", None)
                                        process_mode = getattr(file, "process_mode", "direct")
                                    
                                    # åªæœ‰ direct æ¨¡å¼çš„æ–‡ä»¶æ‰æ·»åŠ åˆ° input_fileï¼ˆä»…æ”¯æŒ PDFï¼‰
                                    if openai_file_id and process_mode == "direct":
                                        content_parts.append({
                                            "type": "input_file",
                                            "file_id": openai_file_id
                                        })
                            
                            # å¦‚æœæ²¡æœ‰å†…å®¹éƒ¨åˆ†ï¼Œæ·»åŠ ç©ºæ–‡æœ¬
                            if not content_parts:
                                content_parts.append({"type": "input_text", "text": ""})
                            
                            input_messages.append({
                                "role": role,
                                "content": content_parts
                            })
                    
                    # å‡†å¤‡å·¥å…·é…ç½®
                    tools_config = self._prepare_tools_config(messages, tools)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡ç”Ÿæˆå·¥å…·å¹¶æŸ¥æ‰¾ä¹‹å‰çš„å›¾ç‰‡ç”Ÿæˆç»“æœ
                    previous_image_gen_id = ""
                    has_image_gen_tool = tools and any(tool.get("type") == "image_generation" for tool in tools)
                    if has_image_gen_tool:
                        previous_image_gen_id = self._find_previous_image_generation(messages)
                    
                    # ä½¿ç”¨ç»“æ„åŒ–è¾“å…¥æ ¼å¼
                    # å°†å‰ç«¯çš„ 'instant' æ˜ å°„ä¸º OpenAI API çš„ 'minimal'
                    effort_value = "minimal" if reasoning == "instant" else reasoning
                    completion_params = {
                        "model": model,
                        "input": input_messages,
                        "reasoning": {
                            "effort": effort_value,
                            "summary": reasoning_summaries if reasoning_summaries != "auto" else "auto"
                        }
                    }
                    
                    # å¦‚æœæœ‰ä¹‹å‰çš„å›¾ç‰‡ç”Ÿæˆç»“æœï¼Œæ·»åŠ åˆ°è¯·æ±‚ä¸­ï¼ˆç”¨äºå¤šè½®å›¾åƒç”Ÿæˆï¼‰
                    if previous_image_gen_id:
                        completion_params["previous_response_id"] = previous_image_gen_id
                        logger.info(f"ä½¿ç”¨previous_response_idè¿›è¡Œå¤šè½®å›¾åƒç”Ÿæˆ: {previous_image_gen_id}")
                    
                    # æ·»åŠ å·¥å…·é…ç½®
                    if tools_config["tools"]:
                        completion_params.update(tools_config)
                        # å¦‚æœæœ‰å·¥å…·ä¸”æ˜¯å¿…éœ€çš„ï¼Œè®¾ç½® tool_choice
                        need_code_interpreter = any(tool.get("type") == "code_interpreter" for tool in tools_config["tools"])
                        if need_code_interpreter:
                            completion_params["tool_choice"] = "required"
                    
                else:
                    # çº¯æ–‡æœ¬æ¨¡å¼ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
                    input_text = ""
                    
                    for msg in messages:
                        role = self._get_message_attr(msg, "role")
                        content = self._get_message_attr(msg, "content")
                        
                        if role == "system":
                            instructions_text = content
                        elif role == "user":
                            input_text += f"{content}\n"
                        elif role == "assistant":
                            input_text += f"Assistant: {content}\n"
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡ç”Ÿæˆå·¥å…·å¹¶æŸ¥æ‰¾ä¹‹å‰çš„å›¾ç‰‡ç”Ÿæˆç»“æœ
                    previous_image_gen_id = ""
                    has_image_gen_tool = tools and any(tool.get("type") == "image_generation" for tool in tools)
                    if has_image_gen_tool:
                        previous_image_gen_id = self._find_previous_image_generation(messages)
                    
                    # å°†å‰ç«¯çš„ 'instant' æ˜ å°„ä¸º OpenAI API çš„ 'minimal'
                    effort_value = "minimal" if reasoning == "instant" else reasoning
                    completion_params = {
                        "model": model,
                        "input": input_text.strip(),
                        "reasoning": {
                            "effort": effort_value,
                            "summary": reasoning_summaries if reasoning_summaries != "auto" else "auto"
                        }
                    }
                    
                    # å¦‚æœæœ‰ä¹‹å‰çš„å›¾ç‰‡ç”Ÿæˆç»“æœï¼Œæ·»åŠ åˆ°è¯·æ±‚ä¸­ï¼ˆç”¨äºå¤šè½®å›¾åƒç”Ÿæˆï¼‰
                    if previous_image_gen_id:
                        completion_params["previous_response_id"] = previous_image_gen_id
                        logger.info(f"ä½¿ç”¨previous_response_idè¿›è¡Œå¤šè½®å›¾åƒç”Ÿæˆ: {previous_image_gen_id}")
                
                # æ·»åŠ  instructions å¦‚æœæœ‰ system æ¶ˆæ¯
                if instructions_text:
                    completion_params["instructions"] = instructions_text
                
                # GPT-5 ç³»åˆ—æ¨¡å‹ä½¿ç”¨ max_output_tokens (ä¸æ˜¯ max_completion_tokens)
                completion_params["max_output_tokens"] = 4000
                
                # å‡†å¤‡å·¥å…·é…ç½®å¹¶æ·»åŠ åˆ°è¯·æ±‚ä¸­
                tools_config = self._prepare_tools_config(messages, tools, "openai")
                if tools_config["tools"]:
                    completion_params.update(tools_config)
                
                # æ‰“å°å®é™…å‘é€çš„ JSON
                logger.info(f"ğŸ“¤ å‘é€ç»™ OpenAI Responses API çš„å®Œæ•´è¯·æ±‚: {json.dumps(completion_params, ensure_ascii=False, indent=2)}")
                logger.info(f"ä½¿ç”¨ Responses API å‚æ•°æ ¼å¼{'ï¼ˆåŒ…å«æ–‡ä»¶æ”¯æŒï¼‰' if has_files else 'ï¼ˆçº¯æ–‡æœ¬æ¨¡å¼ï¼‰'}")
                
                # è°ƒç”¨ Responses API
                try:
                    response = await asyncio.wait_for(
                        client.responses.create(**completion_params),
                        timeout=timeout
                    )
                except AttributeError as e:
                    # Responses API ä¸å¯ç”¨æ—¶æŠ›å‡ºé”™è¯¯ï¼Œä¸å†å›é€€
                    logger.error("Responses API ä¸å¯ç”¨ï¼Œè¯·å‡çº§ OpenAI SDK åˆ°æœ€æ–°ç‰ˆæœ¬")
                    raise Exception(f"Responses API ä¸å¯ç”¨: {str(e)}. è¯·è¿è¡Œ: pip install --upgrade openai")
            else:
                # æ ‡å‡†çš„ Responses API è°ƒç”¨ï¼ˆå¯¹äºå…¶ä»–é GPT-5 æ€è€ƒæ¨¡å¼çš„æ¨¡å‹ï¼‰
                # è½¬æ¢æ¶ˆæ¯ä¸º Responses API æ ¼å¼
                input_messages = []
                instructions_text = ""

                for msg in messages:
                    role = self._get_message_attr(msg, "role")
                    content = self._get_message_attr(msg, "content")

                    if role == "system":
                        instructions_text = content
                    else:
                        input_messages.append({
                            "role": role,
                            "content": content
                        })

                completion_params = {
                    "model": model,
                    "input": input_messages
                }

                # æ·»åŠ  instructions
                if instructions_text:
                    completion_params["instructions"] = instructions_text

                # å‡†å¤‡å·¥å…·é…ç½®
                tools_config = self._prepare_tools_config(messages, tools, "openai")
                if tools_config["tools"]:
                    completion_params["tools"] = tools_config["tools"]

                # GPT-5 ç³»åˆ—æ¨¡å‹ä¸æ”¯æŒè‡ªå®šä¹‰ temperatureï¼Œä½¿ç”¨é»˜è®¤å€¼ 1
                if not self._is_gpt5_model(model):
                    completion_params["temperature"] = 0.7

                # ä½¿ç”¨ max_output_tokensï¼ˆResponses API çš„å‚æ•°ï¼‰
                completion_params["max_output_tokens"] = 4000

                # ä½¿ç”¨ Responses API
                response = await asyncio.wait_for(
                    client.responses.create(**completion_params),
                    timeout=timeout
                )
            
            result = response.model_dump()
            logger.info(f"OpenAI Responses APIè°ƒç”¨æˆåŠŸ")
            
            # è½¬æ¢ Responses API æ ¼å¼ä¸ºæ ‡å‡† Chat Completions æ ¼å¼
            converted_result = self._convert_responses_to_chat_format(result)
            return converted_result
            
        except Exception as e:
            logger.error(f"OpenAI Responses APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise Exception(f"OpenAI Responses APIè°ƒç”¨å¤±è´¥: {str(e)}")

    def _convert_message_to_anthropic_format(self, msg: Union[Dict[str, Any], Any]) -> Dict[str, Any]:
        """å°†æ¶ˆæ¯è½¬æ¢ä¸ºAnthropic Messages APIæ ¼å¼ï¼Œæ”¯æŒå›¾ç‰‡ã€æ–‡ä»¶ã€æœç´¢ç»“æœå’Œå¼•ç”¨"""
        role = self._get_message_attr(msg, "role")
        content = self._get_message_attr(msg, "content")
        
        # è·å–å¤šåª’ä½“å’Œé™„åŠ æ•°æ®
        images = None
        files = None
        search_results = None
        citations_enabled = False
        
        if isinstance(msg, dict):
            images = msg.get("images")
            files = msg.get("files")
            search_results = msg.get("search_results")
            citations_enabled = msg.get("citations_enabled", False)
        else:
            images = getattr(msg, "images", None)
            files = getattr(msg, "files", None)
            search_results = getattr(msg, "search_results", None)
            citations_enabled = getattr(msg, "citations_enabled", False)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤šåª’ä½“å†…å®¹
        has_multimedia = (images and len(images) > 0) or (files and len(files) > 0) or (search_results and len(search_results) > 0)
        
        # å¦‚æœæ²¡æœ‰å¤šåª’ä½“å†…å®¹ï¼Œä½¿ç”¨ä¼ ç»Ÿæ ¼å¼
        if not has_multimedia:
            return {"role": role, "content": content}
        
        # æ„é€ æ”¯æŒå¤šåª’ä½“çš„æ¶ˆæ¯æ ¼å¼
        content_parts = []
        
        # æ·»åŠ æ–‡æœ¬å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
        if content and content.strip():
            content_parts.append({"type": "text", "text": content})
        
        # æ·»åŠ å›¾ç‰‡å†…å®¹ï¼ˆVisionæ”¯æŒï¼‰
        if images:
            for image in images:
                if isinstance(image, dict):
                    image_data = image.get("data")
                    mime_type = image.get("mime_type", "image/jpeg")
                else:
                    image_data = getattr(image, "data", "")
                    mime_type = getattr(image, "mime_type", "image/jpeg")
                
                if image_data:
                    content_parts.append({
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": mime_type,
                            "data": image_data
                        }
                    })
        
        # æ·»åŠ æ–‡ä»¶å†…å®¹ï¼ˆæ ¹æ®ç±»å‹åˆ†æµä¸ºimageæˆ–documentï¼‰
        if files:
            for file in files:
                if isinstance(file, dict):
                    file_id = file.get("anthropic_file_id")
                    filename = file.get("filename")
                    file_data = file.get("data")  # base64æ•°æ®
                    mime_type = file.get("mime_type", "application/octet-stream")
                    file_url = file.get("url")  # URLæ–¹å¼
                else:
                    file_id = getattr(file, "anthropic_file_id", "")
                    filename = getattr(file, "filename", "")
                    file_data = getattr(file, "data", "")
                    mime_type = getattr(file, "mime_type", "application/octet-stream")
                    file_url = getattr(file, "url", "")
                
                # æ ¹æ®MIMEç±»å‹åˆ¤æ–­æ˜¯å›¾ç‰‡è¿˜æ˜¯æ–‡æ¡£
                if mime_type.startswith("image/"):
                    # å›¾ç‰‡æ–‡ä»¶ï¼šä½œä¸ºimage contentå¤„ç†ï¼ˆVisionæ”¯æŒï¼‰
                    if file_id:
                        # ä½¿ç”¨Files APIä¸Šä¼ çš„å›¾ç‰‡
                        content_parts.append({
                            "type": "image",
                            "source": {
                                "type": "file",
                                "file_id": file_id
                            }
                        })
                    elif file_url:
                        # URLæ–¹å¼çš„å›¾ç‰‡
                        content_parts.append({
                            "type": "image",
                            "source": {
                                "type": "url",
                                "url": file_url
                            }
                        })
                    elif file_data:
                        # Base64æ–¹å¼çš„å›¾ç‰‡
                        content_parts.append({
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": mime_type,
                                "data": file_data
                            }
                        })
                else:
                    # éå›¾ç‰‡æ–‡ä»¶ï¼šä½œä¸ºdocument contentå¤„ç†ï¼ˆPDFã€æ–‡æ¡£ç­‰ï¼‰
                    if file_id:
                        # ä½¿ç”¨Files APIä¸Šä¼ çš„æ–‡æ¡£
                        content_parts.append({
                            "type": "document",
                            "source": {
                                "type": "file",
                                "file_id": file_id
                            }
                        })
                    elif file_url:
                        # URLæ–¹å¼çš„æ–‡æ¡£
                        content_parts.append({
                            "type": "document",
                            "source": {
                                "type": "url",
                                "url": file_url
                            }
                        })
                    elif file_data and mime_type == "application/pdf":
                        # Base64æ–¹å¼çš„PDFæ–‡æ¡£
                        content_parts.append({
                            "type": "document",
                            "source": {
                                "type": "base64",
                                "media_type": mime_type,
                                "data": file_data
                            }
                        })
                    elif file_data and (mime_type.startswith("text/") or mime_type in ["application/json", "application/xml"]):
                        # æ–‡æœ¬ç±»æ–‡æ¡£ï¼ˆéœ€è¦è§£ç base64ä¸ºæ–‡æœ¬ï¼‰
                        try:
                            import base64
                            if file_data.strip():  # æ£€æŸ¥æ˜¯å¦ä¸ºbase64
                                try:
                                    text_content = base64.b64decode(file_data).decode('utf-8')
                                except:
                                    text_content = file_data  # å‡è®¾å·²ç»æ˜¯æ–‡æœ¬
                            else:
                                text_content = file_data
                            
                            content_parts.append({
                                "type": "document",
                                "source": {
                                    "type": "base64",
                                    "media_type": mime_type,
                                    "data": file_data
                                }
                            })
                        except Exception as e:
                            # å¦‚æœè§£ç å¤±è´¥ï¼Œä»ç„¶æŒ‰åŸå§‹æ•°æ®å¤„ç†
                            content_parts.append({
                                "type": "document", 
                                "source": {
                                    "type": "base64",
                                    "media_type": mime_type,
                                    "data": file_data
                                }
                            })
        
        # æ·»åŠ æœç´¢ç»“æœå†…å®¹ï¼ˆSearch Resultsæ”¯æŒï¼‰
        if search_results:
            for result in search_results:
                if isinstance(result, dict):
                    source = result.get("source", "")
                    title = result.get("title", "")
                    result_content = result.get("content", "")
                else:
                    source = getattr(result, "source", "")
                    title = getattr(result, "title", "")
                    result_content = getattr(result, "content", "")
                
                if result_content:
                    content_parts.append({
                        "type": "search_result",
                        "source": source,
                        "title": title,
                        "content": [
                            {
                                "type": "text",
                                "text": result_content
                            }
                        ],
                        "citations": {"enabled": citations_enabled}
                    })
        
        return {
            "role": role,
            "content": content_parts
        }

    def _check_uses_files_api(self, messages: List[Dict[str, Any]]) -> bool:
        """æ£€æŸ¥æ¶ˆæ¯ä¸­æ˜¯å¦ä½¿ç”¨äº†Files API"""
        for message in messages:
            content = message.get("content", [])
            if isinstance(content, list):
                for content_block in content:
                    if isinstance(content_block, dict):
                        # æ£€æŸ¥image content blocks
                        if content_block.get("type") == "image":
                            source = content_block.get("source", {})
                            if source.get("type") == "file":
                                return True
                        # æ£€æŸ¥document content blocks
                        elif content_block.get("type") == "document":
                            source = content_block.get("source", {})
                            if source.get("type") == "file":
                                return True
        return False

    async def _anthropic_completion(
        self,
        model: str,
        messages: List[Union[Dict[str, str], Any]],  # Support both dict and Pydantic objects
        api_key: str,
        thinking_mode: bool = False,
        tools: List[Dict[str, Any]] = None,
        stream: bool = False
    ) -> Dict[str, Any]:
        """Anthropic Claude Messages API è°ƒç”¨ï¼Œæ”¯æŒExtended Thinkingã€Visionã€Filesã€Citationså’ŒSearch Results"""
        try:
            client = anthropic.AsyncAnthropic(
                api_key=api_key,
                timeout=self.default_timeout
            )
            
            logger.info(f"è°ƒç”¨Anthropicæ¨¡å‹: {model}, æ‰©å±•æ€è€ƒæ¨¡å¼: {thinking_mode}, æµå¼è¾“å‡º: {stream}")
            
            system_message = ""
            user_messages = []
            
            # è½¬æ¢æ¶ˆæ¯æ ¼å¼ä»¥æ”¯æŒå¤šåª’ä½“å†…å®¹
            for msg in messages:
                role = self._get_message_attr(msg, "role")
                content = self._get_message_attr(msg, "content")
                
                if role == "system":
                    system_message = content
                else:
                    # è½¬æ¢ä¸ºAnthropic Messages APIæ ¼å¼
                    converted_msg = self._convert_message_to_anthropic_format(msg)
                    user_messages.append(converted_msg)
            
            # æ„å»ºè¯·æ±‚å‚æ•°
            kwargs = {
                "model": model,
                "max_tokens": 4000,
                "messages": user_messages,
                "temperature": 0.7,
                "stream": stream
            }
            
            # æ·»åŠ systemæ¶ˆæ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            if system_message:
                kwargs["system"] = system_message
            
            # Extended Thinkingæ”¯æŒï¼ˆClaudeä¸å…è®¸ç”¨æˆ·è®¾ç½®budget_tokensï¼Œä½¿ç”¨å›ºå®šå€¼10000ï¼‰
            if thinking_mode:
                kwargs["thinking"] = {
                    "type": "enabled",
                    "budget_tokens": 10000  # å›ºå®šå€¼ï¼Œå¦‚æ–‡æ¡£è¦æ±‚
                }
                logger.info("å¯ç”¨Claudeæ‰©å±•æ€è€ƒæ¨¡å¼ï¼Œbudget_tokens: 10000")
            
            # å·¥å…·é…ç½®ï¼ˆå¦‚æœæœ‰ï¼‰
            if tools:
                # ä½¿ç”¨Anthropicä¸“ç”¨çš„å·¥å…·é…ç½®
                tools_config = self._prepare_tools_config(messages, tools, "anthropic")

                # æ·»åŠ function callingå·¥å…·
                if tools_config["tools"]:
                    kwargs["tools"] = tools_config["tools"]

                # æ·»åŠ MCPæœåŠ¡å™¨
                if tools_config["mcp_servers"]:
                    kwargs["mcp_servers"] = tools_config["mcp_servers"]
                    # å§‹ç»ˆæ·»åŠ MCP betaå¤´éƒ¨ï¼ˆå¦‚æœMCPæœåŠ¡å™¨å­˜åœ¨ï¼‰
                    kwargs["betas"] = kwargs.get("betas", [])
                    if "mcp-client-2025-04-04" not in kwargs["betas"]:
                        kwargs["betas"].append("mcp-client-2025-04-04")

                # å¤„ç†web searchå·¥å…·ï¼ˆä½¿ç”¨åŸæœ‰é€»è¾‘ï¼‰
                web_search_tools = self._convert_tools_to_anthropic_format(tools)
                if web_search_tools:
                    if "tools" not in kwargs:
                        kwargs["tools"] = []
                    kwargs["tools"].extend(web_search_tools)
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†Files APIï¼Œå¦‚æœæ˜¯åˆ™æ·»åŠ betaså‚æ•°
            uses_files_api = self._check_uses_files_api(user_messages)
            if uses_files_api:
                kwargs["betas"] = ["files-api-2025-04-14"]
                logger.info("æ£€æµ‹åˆ°Files APIä½¿ç”¨ï¼Œå·²æ·»åŠ betaså‚æ•°")
            
            # è°ƒç”¨Anthropic Messages API
            if uses_files_api:
                response = await asyncio.wait_for(
                    client.beta.messages.create(**kwargs),
                    timeout=self.default_timeout
                )
            else:
                response = await asyncio.wait_for(
                    client.messages.create(**kwargs),
                    timeout=self.default_timeout
                )
            
            # è½¬æ¢å“åº”ä¸ºOpenAIå…¼å®¹æ ¼å¼
            result = self._convert_anthropic_response_to_openai_format(response, thinking_mode)
            
            logger.info(f"Anthropic APIè°ƒç”¨æˆåŠŸï¼Œå“åº”å†…å®¹å—æ•°é‡: {len(response.content) if hasattr(response, 'content') else 0}")
            return result
            
        except anthropic.AuthenticationError as e:
            logger.error(f"Anthropicè®¤è¯å¤±è´¥: {str(e)}")
            raise Exception("Anthropic APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥æ‚¨çš„APIå¯†é’¥")
        except anthropic.RateLimitError as e:
            logger.error(f"Anthropicé€Ÿç‡é™åˆ¶: {str(e)}")
            raise Exception("Anthropic APIè¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•")
        except Exception as e:
            logger.error(f"Anthropic APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise Exception(f"Anthropic APIè°ƒç”¨å¤±è´¥: {str(e)}")

    def _convert_tools_to_anthropic_format(self, tools: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å°†å·¥å…·é…ç½®è½¬æ¢ä¸ºAnthropicæ ¼å¼"""
        anthropic_tools = []
        
        for tool in tools:
            tool_type = tool.get("type")
            
            if tool_type == "web_search" or tool_type == "web_search_20250305":
                # Web Searchå·¥å…· - æ”¯æŒAnthropic web_search_20250305æ ¼å¼
                anthropic_tool = {
                    "type": "web_search_20250305",
                    "name": "web_search"
                }
                
                # æ·»åŠ å¯é€‰å‚æ•°
                if tool.get("max_uses"):
                    anthropic_tool["max_uses"] = tool.get("max_uses", 5)
                
                if tool.get("user_location"):
                    anthropic_tool["user_location"] = tool.get("user_location")
                
                if tool.get("allowed_domains"):
                    anthropic_tool["allowed_domains"] = tool.get("allowed_domains")
                
                if tool.get("blocked_domains"):
                    anthropic_tool["blocked_domains"] = tool.get("blocked_domains")
                
                anthropic_tools.append(anthropic_tool)
            
            # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å…¶ä»–å·¥å…·ç±»å‹çš„æ”¯æŒ
        
        return anthropic_tools

    def _convert_anthropic_response_to_openai_format(self, response: Any, thinking_mode: bool = False) -> Dict[str, Any]:
        """å°†Anthropicå“åº”è½¬æ¢ä¸ºOpenAIå…¼å®¹æ ¼å¼"""
        content_text = ""
        thinking_content = ""
        citations = []
        tool_calls = []
        mcp_tool_uses = []
        mcp_tool_results = []

        # å¤„ç†å“åº”å†…å®¹
        if hasattr(response, 'content') and response.content:
            for content_block in response.content:
                if hasattr(content_block, 'type'):
                    if content_block.type == "text":
                        # æ–‡æœ¬å†…å®¹
                        content_text += getattr(content_block, 'text', '')

                        # æå–citationsï¼ˆå¦‚æœæœ‰ï¼‰
                        if hasattr(content_block, 'citations') and content_block.citations:
                            for citation in content_block.citations:
                                citations.append({
                                    "type": getattr(citation, 'type', 'unknown'),
                                    "cited_text": getattr(citation, 'cited_text', ''),
                                    "source": getattr(citation, 'source', ''),
                                    "title": getattr(citation, 'title', ''),
                                    "document_index": getattr(citation, 'document_index', 0),
                                    "start_char_index": getattr(citation, 'start_char_index', 0),
                                    "end_char_index": getattr(citation, 'end_char_index', 0)
                                })

                    elif content_block.type == "thinking" and thinking_mode:
                        # æ‰©å±•æ€è€ƒå†…å®¹
                        thinking_content = getattr(content_block, 'content', '') or getattr(content_block, 'thinking', '')

                    elif content_block.type == "tool_use":
                        # æ ‡å‡†function callingå·¥å…·ä½¿ç”¨
                        tool_call = {
                            "id": getattr(content_block, 'id', ''),
                            "type": "function",
                            "function": {
                                "name": getattr(content_block, 'name', ''),
                                "arguments": json.dumps(getattr(content_block, 'input', {}))
                            }
                        }
                        tool_calls.append(tool_call)

                    elif content_block.type == "mcp_tool_use":
                        # MCPå·¥å…·ä½¿ç”¨
                        mcp_tool_use = {
                            "id": getattr(content_block, 'id', ''),
                            "type": "mcp_tool_use",
                            "name": getattr(content_block, 'name', ''),
                            "server_name": getattr(content_block, 'server_name', ''),
                            "input": getattr(content_block, 'input', {})
                        }
                        mcp_tool_uses.append(mcp_tool_use)

                    elif content_block.type == "mcp_tool_result":
                        # MCPå·¥å…·ç»“æœ
                        mcp_tool_result = {
                            "tool_use_id": getattr(content_block, 'tool_use_id', ''),
                            "type": "mcp_tool_result",
                            "is_error": getattr(content_block, 'is_error', False),
                            "content": getattr(content_block, 'content', []),
                            "server_name": getattr(content_block, 'server_name', ''),
                            "execution_time": getattr(content_block, 'execution_time', None)
                        }
                        mcp_tool_results.append(mcp_tool_result)
        
        # æ„å»ºæ¶ˆæ¯å¯¹è±¡
        message = {
            "role": "assistant",
            "content": content_text
        }
        
        # æ·»åŠ æ€è€ƒå†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
        if thinking_content and thinking_mode:
            message["reasoning"] = thinking_content
        
        # æ·»åŠ citationsï¼ˆå¦‚æœæœ‰ï¼‰
        if citations:
            message["citations"] = citations

        # æ·»åŠ æ ‡å‡†function callingå·¥å…·è°ƒç”¨ï¼ˆå¦‚æœæœ‰ï¼‰
        if tool_calls:
            message["tool_calls"] = tool_calls

        # æ·»åŠ MCPå·¥å…·ä½¿ç”¨å’Œç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
        if mcp_tool_uses:
            message["mcp_tool_uses"] = mcp_tool_uses

        if mcp_tool_results:
            message["mcp_tool_results"] = mcp_tool_results

        # æ„å»ºå®Œæ•´å“åº”
        result = {
            "id": f"msg_{getattr(response, 'id', 'unknown')}",
            "choices": [{
                "message": message,
                "finish_reason": self._map_anthropic_stop_reason(getattr(response, 'stop_reason', None))
            }],
            "usage": {
                "prompt_tokens": getattr(response.usage, 'input_tokens', 0) if hasattr(response, 'usage') else 0,
                "completion_tokens": getattr(response.usage, 'output_tokens', 0) if hasattr(response, 'usage') else 0,
                "total_tokens": (getattr(response.usage, 'input_tokens', 0) + getattr(response.usage, 'output_tokens', 0)) if hasattr(response, 'usage') else 0
            }
        }
        
        return result

    def _map_anthropic_stop_reason(self, stop_reason: str) -> str:
        """æ˜ å°„Anthropicçš„åœæ­¢åŸå› åˆ°OpenAIæ ¼å¼"""
        mapping = {
            "end_turn": "stop",
            "max_tokens": "length",
            "tool_use": "tool_calls",
            "mcp_tool_use": "mcp_tool_calls"
        }
        return mapping.get(stop_reason, "stop")

    async def _google_completion(
        self,
        model: str,
        messages: List[Union[Dict[str, str], Any]],
        api_key: str,
        stream: bool = False,
        thinking_mode: bool = False,
        reasoning_summaries: str = "auto",
        reasoning: str = "medium",
        tools: List[Dict[str, Any]] = None,
        use_native_search: bool = None
    ) -> Dict[str, Any]:
        """Google Gemini API è°ƒç”¨ - å®Œæ•´å®ç°"""
        try:
            genai.configure(api_key=api_key)

            logger.info(f"è°ƒç”¨Googleæ¨¡å‹: {model}, æµå¼: {stream}")

            # è½¬æ¢æ¶ˆæ¯æ ¼å¼å’Œå¤šæ¨¡æ€å†…å®¹
            history = []
            system_instruction = None

            # å¤„ç†ç³»ç»Ÿæ¶ˆæ¯
            for i, msg in enumerate(messages):
                role = self._get_message_attr(msg, "role")
                content = self._get_message_attr(msg, "content")

                if role == "system":
                    system_instruction = content
                    continue
                elif i == len(messages) - 1:
                    # æœ€åä¸€æ¡æ¶ˆæ¯å•ç‹¬å¤„ç†
                    break
                elif role == "user":
                    # å¤„ç†å¤šæ¨¡æ€å†…å®¹
                    parts = self._convert_message_to_gemini_parts(msg)
                    history.append({"role": "user", "parts": parts})
                elif role == "assistant":
                    history.append({"role": "model", "parts": [content]})

            # é…ç½®ç”Ÿæˆå‚æ•°
            generation_config = {
                "temperature": 0.7,
                "max_output_tokens": 8192,
            }

            # å¤„ç†thinking mode
            if thinking_mode and model.startswith("gemini-2.0"):
                generation_config["thinking_budget"] = self._get_thinking_budget(reasoning)

            # è½¬æ¢å·¥å…·
            gemini_tools = None
            if tools:
                gemini_tools = self._convert_tools_to_gemini_format(tools)

            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            model_instance = genai.GenerativeModel(
                model_name=model,
                generation_config=generation_config,
                system_instruction=system_instruction,
                tools=gemini_tools
            )

            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾åƒç”Ÿæˆå·¥å…·
            has_image_generation_tool = tools and any(tool.get("type") == "image_generation" for tool in tools)

            # å¤„ç†æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
            last_message = messages[-1]
            user_parts = self._convert_message_to_gemini_parts(last_message)

            # å¦‚æœæœ‰å›¾åƒç”Ÿæˆå·¥å…·ï¼Œä½¿ç”¨ä¸“é—¨çš„å›¾åƒç”Ÿæˆæ¨¡å‹
            if has_image_generation_tool:
                return await self._handle_google_image_generation(
                    user_parts, api_key, tools, model
                )

            # ç”Ÿæˆå“åº”
            if stream:
                return await self._google_stream_completion(
                    model_instance, history, user_parts
                )
            else:
                chat = model_instance.start_chat(history=history)
                response = await asyncio.wait_for(
                    chat.send_message_async(user_parts),
                    timeout=self.default_timeout
                )

                return self._convert_gemini_response_to_openai_format(response, model)

        except Exception as e:
            logger.error(f"Google APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise Exception(f"Google APIè°ƒç”¨å¤±è´¥: {str(e)}")

    def _convert_message_to_gemini_parts(self, msg):
        """å°†æ¶ˆæ¯è½¬æ¢ä¸ºGemini Partsæ ¼å¼ï¼Œæ”¯æŒå¤šæ¨¡æ€"""
        content = self._get_message_attr(msg, "content")

        # è·å–å›¾ç‰‡æ•°æ®
        images = None
        if isinstance(msg, dict):
            images = msg.get("images")
        else:
            images = getattr(msg, "images", None)

        parts = []

        # æ·»åŠ æ–‡æœ¬å†…å®¹
        if content and content.strip():
            parts.append(content)

        # æ·»åŠ å›¾ç‰‡å†…å®¹
        if images:
            for image in images:
                if isinstance(image, dict):
                    image_data = image.get("data")
                    mime_type = image.get("mime_type", "image/jpeg")
                else:
                    image_data = getattr(image, "data", "")
                    mime_type = getattr(image, "mime_type", "image/jpeg")

                if image_data:
                    import base64
                    try:
                        # è§£ç base64å›¾ç‰‡æ•°æ®
                        image_bytes = base64.b64decode(image_data)
                        parts.append({
                            "mime_type": mime_type,
                            "data": image_bytes
                        })
                    except Exception as e:
                        logger.warning(f"è§£ç å›¾ç‰‡æ•°æ®å¤±è´¥: {e}")

        return parts if parts else [content or ""]

    def _convert_tools_to_gemini_format(self, tools):
        """å°†å·¥å…·è½¬æ¢ä¸ºGeminiæ ¼å¼"""
        gemini_tools = []

        for tool in tools:
            if tool.get("type") == "function":
                function_info = tool.get("function", {})
                gemini_tools.append({
                    "function_declarations": [{
                        "name": function_info.get("name"),
                        "description": function_info.get("description"),
                        "parameters": function_info.get("parameters", {})
                    }]
                })

        return gemini_tools

    def _get_thinking_budget(self, reasoning):
        """æ ¹æ®reasoningçº§åˆ«è·å–thinking budget"""
        budget_map = {
            "low": 1000,
            "medium": 5000,
            "high": 10000
        }
        return budget_map.get(reasoning, 5000)

    async def _google_stream_completion(self, model_instance, history, user_parts):
        """Googleæµå¼å“åº”å¤„ç†"""
        try:
            chat = model_instance.start_chat(history=history)
            response_stream = chat.send_message_stream(user_parts)

            # æ”¶é›†æµå¼å“åº”
            full_text = ""
            async for chunk in response_stream:
                if chunk.text:
                    full_text += chunk.text

            # ç­‰å¾…æµå®Œæˆ
            await response_stream.resolve()
            final_response = response_stream.response

            return self._convert_gemini_response_to_openai_format(final_response, model_instance.model_name)

        except Exception as e:
            logger.error(f"Googleæµå¼å“åº”å¤±è´¥: {str(e)}")
            raise

    def _convert_gemini_response_to_openai_format(self, response, model):
        """å°†Geminiå“åº”è½¬æ¢ä¸ºOpenAIæ ¼å¼"""
        choices = []

        # å¤„ç†å€™é€‰å“åº”
        for i, candidate in enumerate(response.candidates):
            content = ""
            tool_calls = []

            # æå–æ–‡æœ¬å†…å®¹
            for part in candidate.content.parts:
                if hasattr(part, 'text') and part.text:
                    content += part.text
                elif hasattr(part, 'function_call'):
                    # å¤„ç†å‡½æ•°è°ƒç”¨
                    func_call = part.function_call
                    tool_calls.append({
                        "id": f"call_{hash(func_call.name)}",
                        "type": "function",
                        "function": {
                            "name": func_call.name,
                            "arguments": json.dumps(dict(func_call.args))
                        }
                    })

            # æ„å»ºæ¶ˆæ¯
            message = {
                "role": "assistant",
                "content": content
            }

            if tool_calls:
                message["tool_calls"] = tool_calls

            choices.append({
                "index": i,
                "message": message,
                "finish_reason": self._convert_gemini_finish_reason(candidate.finish_reason)
            })

        return {
            "id": f"gemini_{hash(str(response)) % 1000000}",
            "object": "chat.completion",
            "created": int(time.time()),
            "model": model,
            "choices": choices,
            "usage": {
                "prompt_tokens": getattr(response.usage_metadata, 'prompt_token_count', 0) if hasattr(response, 'usage_metadata') else 0,
                "completion_tokens": getattr(response.usage_metadata, 'candidates_token_count', 0) if hasattr(response, 'usage_metadata') else 0,
                "total_tokens": getattr(response.usage_metadata, 'total_token_count', 0) if hasattr(response, 'usage_metadata') else 0
            }
        }

    def _convert_gemini_finish_reason(self, finish_reason):
        """è½¬æ¢Gemini finish_reasonåˆ°OpenAIæ ¼å¼"""
        mapping = {
            "STOP": "stop",
            "MAX_TOKENS": "length",
            "SAFETY": "content_filter",
            "RECITATION": "content_filter",
            "OTHER": "stop"
        }
        return mapping.get(str(finish_reason), "stop")

    async def _handle_google_image_generation(
        self,
        user_parts: List[Any],
        api_key: str,
        tools: List[Dict[str, Any]],
        model: str
    ) -> Dict[str, Any]:
        """å¤„ç†Googleå›¾åƒç”Ÿæˆå·¥å…·è°ƒç”¨"""
        try:
            genai.configure(api_key=api_key)

            # æå–å›¾åƒç”Ÿæˆå·¥å…·é…ç½®
            image_gen_tool = None
            for tool in tools:
                if tool.get("type") == "image_generation":
                    image_gen_tool = tool
                    break

            if not image_gen_tool:
                raise Exception("æœªæ‰¾åˆ°å›¾åƒç”Ÿæˆå·¥å…·é…ç½®")

            # æ„å»ºå›¾åƒç”Ÿæˆæç¤º
            prompt_text = ""
            if isinstance(user_parts, list):
                for part in user_parts:
                    if isinstance(part, str):
                        prompt_text += part + " "
                    elif isinstance(part, dict) and "text" in part:
                        prompt_text += part["text"] + " "
            else:
                prompt_text = str(user_parts)

            # æ„å»ºå®Œæ•´çš„å›¾åƒç”Ÿæˆæç¤º
            image_prompt = f"Generate an image: {prompt_text.strip()}"

            # æ ¹æ®å·¥å…·é…ç½®è°ƒæ•´æç¤º
            style = image_gen_tool.get("style", "natural")
            quality = image_gen_tool.get("quality", "standard")

            if style == "artistic":
                image_prompt += " in artistic style"
            elif style == "photorealistic":
                image_prompt += " in photorealistic style"
            elif style == "digital_art":
                image_prompt += " in digital art style"

            if quality == "hd":
                image_prompt += " with high detail and quality"

            logger.info(f"Googleå›¾åƒç”Ÿæˆæç¤º: {image_prompt}")

            # ä½¿ç”¨Gemini 2.5 Flash Imageæ¨¡å‹ç”Ÿæˆå›¾åƒ
            image_model = "gemini-2.5-flash-image" if model != "gemini-2.5-flash-image" else model
            model_instance = genai.GenerativeModel(image_model)

            response = await asyncio.wait_for(
                model_instance.generate_content_async(
                    image_prompt,
                    generation_config={
                        "temperature": 0.8,
                        "max_output_tokens": 8192,
                    }
                ),
                timeout=self.default_timeout * 2  # å›¾åƒç”Ÿæˆéœ€è¦æ›´é•¿æ—¶é—´
            )

            # å¤„ç†å›¾åƒç”Ÿæˆç»“æœ
            image_generations = []

            # æ£€æŸ¥å“åº”ä¸­æ˜¯å¦åŒ…å«å›¾ç‰‡
            if hasattr(response, 'candidates') and response.candidates:
                for candidate in response.candidates:
                    if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                        for part in candidate.content.parts:
                            # æ£€æŸ¥æ˜¯å¦ä¸ºå›¾ç‰‡éƒ¨åˆ†
                            if hasattr(part, 'inline_data'):
                                image_data = part.inline_data.data
                                mime_type = part.inline_data.mime_type

                                # è½¬æ¢ä¸ºbase64æ ¼å¼
                                if isinstance(image_data, bytes):
                                    b64_data = base64.b64encode(image_data).decode('utf-8')
                                else:
                                    b64_data = image_data

                                image_gen_result = {
                                    "id": f"img_gen_{int(time.time() * 1000)}",
                                    "type": "image_generation_call",
                                    "status": "completed",
                                    "result": {
                                        "url": f"data:{mime_type};base64,{b64_data}",
                                        "b64_json": b64_data
                                    },
                                    "revised_prompt": prompt_text.strip()
                                }
                                image_generations.append(image_gen_result)

            # å¦‚æœæ²¡æœ‰ç›´æ¥çš„å›¾ç‰‡æ•°æ®ï¼Œä½†æœ‰æ–‡æœ¬å“åº”ï¼Œåˆ™è®¤ä¸ºå›¾åƒç”Ÿæˆè¯·æ±‚è¢«æ¥å—
            if not image_generations and response.text:
                # åˆ›å»ºä¸€ä¸ªè¡¨ç¤ºå›¾åƒç”Ÿæˆè°ƒç”¨çš„è®°å½•
                image_gen_result = {
                    "id": f"img_gen_{int(time.time() * 1000)}",
                    "type": "image_generation_call",
                    "status": "completed",
                    "result": {
                        "description": response.text,
                        "note": "å›¾åƒç”Ÿæˆå®Œæˆï¼Œä½†æ— æ³•æå–ç›´æ¥çš„å›¾åƒæ•°æ®"
                    },
                    "revised_prompt": prompt_text.strip()
                }
                image_generations.append(image_gen_result)

            # æ„å»ºOpenAIå…¼å®¹çš„å“åº”æ ¼å¼
            return {
                "id": f"gemini_img_{int(time.time() * 1000)}",
                "object": "chat.completion",
                "created": int(time.time()),
                "model": image_model,
                "choices": [{
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": "å›¾åƒå·²ç”Ÿæˆå®Œæˆã€‚",
                        "image_generations": image_generations
                    },
                    "finish_reason": "stop"
                }],
                "usage": {
                    "prompt_tokens": len(prompt_text.split()),
                    "completion_tokens": 0,
                    "total_tokens": len(prompt_text.split())
                }
            }

        except Exception as e:
            logger.error(f"Googleå›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}")
            # è¿”å›é”™è¯¯ä½†ä¿æŒOpenAIæ ¼å¼
            return {
                "id": f"gemini_img_error_{int(time.time() * 1000)}",
                "object": "chat.completion",
                "created": int(time.time()),
                "model": model,
                "choices": [{
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": f"å›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}",
                        "image_generations": []
                    },
                    "finish_reason": "stop"
                }],
                "usage": {
                    "prompt_tokens": 0,
                    "completion_tokens": 0,
                    "total_tokens": 0
                }
            }

    async def _google_stream_completion_websocket(
        self,
        model: str,
        messages: List[Union[Dict[str, str], Any]],
        api_key: str,
        thinking_mode: bool = False,
        reasoning_summaries: str = "auto",
        reasoning: str = "medium",
        tools: List[Dict[str, Any]] = None,
        use_native_search: bool = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """Google Gemini WebSocketæµå¼å“åº”"""
        try:
            genai.configure(api_key=api_key)

            logger.info(f"å¼€å§‹Googleæµå¼è°ƒç”¨: {model}")

            # è½¬æ¢æ¶ˆæ¯æ ¼å¼å’Œå¤šæ¨¡æ€å†…å®¹
            history = []
            system_instruction = None

            # å¤„ç†ç³»ç»Ÿæ¶ˆæ¯
            for i, msg in enumerate(messages):
                role = self._get_message_attr(msg, "role")
                content = self._get_message_attr(msg, "content")

                if role == "system":
                    system_instruction = content
                    continue
                elif i == len(messages) - 1:
                    # æœ€åä¸€æ¡æ¶ˆæ¯å•ç‹¬å¤„ç†
                    break
                elif role == "user":
                    # å¤„ç†å¤šæ¨¡æ€å†…å®¹
                    parts = self._convert_message_to_gemini_parts(msg)
                    history.append({"role": "user", "parts": parts})
                elif role == "assistant":
                    history.append({"role": "model", "parts": [content]})

            # é…ç½®ç”Ÿæˆå‚æ•°
            generation_config = {
                "temperature": 0.7,
                "max_output_tokens": 8192,
            }

            # å¤„ç†thinking mode
            if thinking_mode and model.startswith("gemini-2.0"):
                generation_config["thinking_budget"] = self._get_thinking_budget(reasoning)

            # è½¬æ¢å·¥å…·
            gemini_tools = None
            if tools:
                gemini_tools = self._convert_tools_to_gemini_format(tools)

            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            model_instance = genai.GenerativeModel(
                model_name=model,
                generation_config=generation_config,
                system_instruction=system_instruction,
                tools=gemini_tools
            )

            # å¤„ç†æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
            last_message = messages[-1]
            user_parts = self._convert_message_to_gemini_parts(last_message)

            # å¼€å§‹æµå¼å“åº”
            chat = model_instance.start_chat(history=history)
            response_stream = chat.send_message(user_parts, stream=True)

            accumulated_text = ""
            message_id = f"gemini_{int(time.time() * 1000)}"

            for chunk in response_stream:
                if chunk.text:
                    accumulated_text += chunk.text

                    # ç”Ÿæˆæµå¼å“åº”å—
                    yield {
                        "id": message_id,
                        "object": "chat.completion.chunk",
                        "created": int(time.time()),
                        "model": model,
                        "choices": [{
                            "index": 0,
                            "delta": {
                                "content": chunk.text
                            },
                            "finish_reason": None
                        }]
                    }

            # å‘é€å®Œæˆä¿¡å·
            yield {
                "id": message_id,
                "object": "chat.completion.chunk",
                "created": int(time.time()),
                "model": model,
                "choices": [{
                    "index": 0,
                    "delta": {},
                    "finish_reason": "stop"
                }]
            }

        except Exception as e:
            logger.error(f"Googleæµå¼è°ƒç”¨å¤±è´¥: {str(e)}")
            yield {"error": str(e)}

    async def _openai_compatible_completion(
        self,
        model: str,
        messages: List[Union[Dict[str, str], Any]],  # Support both dict and Pydantic objects
        api_key: str,
        stream: bool = False,
        thinking_mode: bool = False,
        reasoning_summaries: str = "auto",
        tools: List[Dict[str, Any]] = None,
        use_native_search: bool = None,
        base_url: str = None
    ) -> Dict[str, Any]:
        """OpenAI å…¼å®¹ API è°ƒç”¨ (Chat Completions API)"""
        try:
            # å¦‚æœæ²¡æœ‰æä¾›base_urlï¼Œä½¿ç”¨é»˜è®¤çš„OpenAI URL
            if not base_url:
                base_url = "https://api.openai.com/v1"
            
            client = openai.AsyncOpenAI(
                api_key=api_key,
                base_url=base_url,
                timeout=self.default_timeout
            )
            
            logger.info(f"è°ƒç”¨OpenAIå…¼å®¹APIæ¨¡å‹: {model}, æ¶ˆæ¯æ•°é‡: {len(messages)}, åŸºç¡€URL: {base_url}")
            
            # è½¬æ¢æ¶ˆæ¯æ ¼å¼ - åªæ”¯æŒåŸºæœ¬çš„æ–‡æœ¬æ¶ˆæ¯æ ¼å¼
            converted_messages = []
            for msg in messages:
                role = self._get_message_attr(msg, "role")
                content = self._get_message_attr(msg, "content")
                converted_messages.append({"role": role, "content": content})
            
            # åŸºç¡€å®Œæˆå‚æ•°ï¼ˆOpenAIå…¼å®¹æä¾›å•†åªæ”¯æŒçº¯æ–‡æœ¬å¯¹è¯ï¼‰
            completion_params = {
                "model": model,
                "messages": converted_messages,
                "stream": stream,
                "temperature": 0.7,
                "max_tokens": 4000
            }
            
            response = await asyncio.wait_for(
                client.chat.completions.create(**completion_params),
                timeout=self.default_timeout
            )
            
            result = response.model_dump()
            logger.info(f"OpenAIå…¼å®¹APIè°ƒç”¨æˆåŠŸï¼Œè¿”å›é€‰æ‹©æ•°é‡: {len(result.get('choices', []))}")
            return result
            
        except openai.AuthenticationError as e:
            logger.error(f"OpenAIå…¼å®¹APIè®¤è¯å¤±è´¥: {str(e)}")
            raise Exception("OpenAIå…¼å®¹APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥æ‚¨çš„APIå¯†é’¥")
        except openai.RateLimitError as e:
            logger.error(f"OpenAIå…¼å®¹APIé€Ÿç‡é™åˆ¶: {str(e)}")
            raise Exception("OpenAIå…¼å®¹APIè¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•")
        except openai.InternalServerError as e:
            logger.error(f"OpenAIå…¼å®¹APIæœåŠ¡å™¨é”™è¯¯: {str(e)}")
            raise Exception("OpenAIå…¼å®¹APIæœåŠ¡å™¨æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•")
        except Exception as e:
            logger.error(f"OpenAIå…¼å®¹APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
            raise Exception(f"OpenAIå…¼å®¹APIè°ƒç”¨å¤±è´¥: {str(e)}")

    async def stream_completion(
        self,
        provider: str,
        model: str,
        messages: List[Union[Dict[str, str], Any]],  # Support both dict and Pydantic objects
        api_key: str,
        thinking_mode: bool = False,
        reasoning_summaries: str = "auto",
        reasoning: str = "medium",
        tools: List[Dict[str, Any]] = None,
        use_native_search: bool = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """æµå¼å®Œæˆï¼ˆWebSocketä½¿ç”¨ï¼‰"""
        logger.info(f"å¼€å§‹æµå¼è°ƒç”¨ {provider} API")
        
        try:
            if provider == "openai":
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒæµå¼è¾“å‡º
                if await self._supports_streaming(provider, model):
                    async for chunk in self._openai_stream_completion(model, messages, api_key, thinking_mode, reasoning_summaries, tools, use_native_search):
                        yield chunk
                else:
                    # ä¸æ”¯æŒæµå¼çš„æ¨¡å‹ï¼Œç›´æ¥è¿”å›å®Œæ•´å“åº”
                    logger.info(f"æ¨¡å‹ {model} ä¸æ”¯æŒæµå¼è¾“å‡ºï¼Œä½¿ç”¨æ™®é€šè¯·æ±‚")
                    response = await self.get_completion(provider, model, messages, api_key, False, thinking_mode, reasoning_summaries, reasoning, tools, use_native_search)
                    yield response
            elif provider == "anthropic":
                # Anthropicæ”¯æŒæµå¼è¾“å‡º
                async for chunk in self._anthropic_stream_completion(model, messages, api_key, thinking_mode, reasoning_summaries, tools, use_native_search):
                    yield chunk
            elif provider == "google":
                # Google Geminiæ”¯æŒæµå¼è¾“å‡º
                async for chunk in self._google_stream_completion_websocket(model, messages, api_key, thinking_mode, reasoning_summaries, reasoning, tools, use_native_search):
                    yield chunk
            elif provider == "openai_compatible":
                # OpenAIå…¼å®¹æä¾›å•†æ”¯æŒæµå¼
                async for chunk in self._openai_compatible_stream_completion(model, messages, api_key, thinking_mode, reasoning_summaries, tools, use_native_search):
                    yield chunk
            else:
                # å…¶ä»–æä¾›å•†æš‚ä¸æ”¯æŒæµå¼
                response = await self.get_completion(provider, model, messages, api_key, False, thinking_mode, reasoning_summaries, reasoning)
                yield response
                
        except Exception as e:
            logger.error(f"æµå¼è°ƒç”¨å¤±è´¥: {str(e)}")
            yield {"error": str(e)}

    async def _openai_stream_completion(
        self,
        model: str,
        messages: List[Union[Dict[str, str], Any]],  # Support both dict and Pydantic objects
        api_key: str,
        thinking_mode: bool = False,
        reasoning_summaries: str = "auto",
        tools: List[Dict[str, Any]] = None,
        use_native_search: bool = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """OpenAIæµå¼å®Œæˆ - ä½¿ç”¨ Responses API"""
        try:
            client = openai.AsyncOpenAI(
                api_key=api_key,
                timeout=self.default_timeout
            )

            # å‡†å¤‡å·¥å…·é…ç½®
            tools_config = self._prepare_tools_config(messages, tools, "openai")

            # è½¬æ¢æ¶ˆæ¯ä¸º Responses API æ ¼å¼
            input_messages = []
            instructions_text = ""

            for msg in messages:
                role = self._get_message_attr(msg, "role")
                content = self._get_message_attr(msg, "content")

                if role == "system":
                    # system æ¶ˆæ¯è½¬æ¢ä¸º instructions
                    instructions_text = content
                else:
                    # å…¶ä»–æ¶ˆæ¯æ·»åŠ åˆ° input
                    input_messages.append({
                        "role": role,
                        "content": content
                    })

            # æ„å»º Responses API å‚æ•°
            stream_params = {
                "model": model,
                "input": input_messages,
                "stream": True
            }

            # æ·»åŠ  instructions
            if instructions_text:
                stream_params["instructions"] = instructions_text

            # æ·»åŠ å·¥å…·é…ç½® (ä¼ é€’åŸå§‹å­—å…¸è€Œä¸æ˜¯Pydanticæ¨¡å‹)
            if tools_config["tools"]:
                # è½¬æ¢å·¥å…·é…ç½®ä¸ºåŸå§‹å­—å…¸æ ¼å¼ï¼Œé¿å…Pydanticåºåˆ—åŒ–è­¦å‘Š
                stream_params["tools"] = [
                    tool if isinstance(tool, dict) else tool
                    for tool in tools_config["tools"]
                ]

            # GPT-5 ç³»åˆ—æ¨¡å‹ä¸æ”¯æŒè‡ªå®šä¹‰ temperatureï¼Œä½¿ç”¨é»˜è®¤å€¼ 1
            if not self._is_gpt5_model(model):
                stream_params["temperature"] = 0.7

            # ä½¿ç”¨ max_output_tokensï¼ˆResponses API çš„å‚æ•°ï¼‰
            stream_params["max_output_tokens"] = 4000

            # ä½¿ç”¨ Responses API è¿›è¡Œæµå¼è°ƒç”¨
            stream = await client.responses.create(**stream_params)

            async for event in stream:
                # è½¬æ¢ Responses API äº‹ä»¶ä¸º Chat Completions æ ¼å¼
                event_dict = event.model_dump() if hasattr(event, 'model_dump') else event
                event_type = event_dict.get('type', '')

                # å¤„ç†æ–‡æœ¬å¢é‡äº‹ä»¶
                if event_type == 'response.output_text.delta':
                    yield {
                        'choices': [{
                            'delta': {
                                'content': event_dict.get('delta', '')
                            },
                            'index': 0,
                            'finish_reason': None
                        }]
                    }

                # å¤„ç†å®Œæˆäº‹ä»¶
                elif event_type == 'response.completed':
                    yield {
                        'choices': [{
                            'delta': {},
                            'index': 0,
                            'finish_reason': 'stop'
                        }]
                    }

                # å¤„ç†é”™è¯¯äº‹ä»¶
                elif event_type == 'response.failed':
                    error_info = event_dict.get('response', {}).get('error', {})
                    yield {
                        'error': error_info.get('message', 'Unknown error')
                    }

                # å¿½ç•¥ä½†è®°å½•çš„äº‹ä»¶ï¼ˆè¿™äº›äº‹ä»¶ä¸éœ€è¦å‘é€ç»™å‰ç«¯ï¼Œä½†è¡¨ç¤ºæµä»åœ¨è¿›è¡Œï¼‰
                elif event_type in [
                    'response.created',
                    'response.in_progress',
                    'response.output_item.added',
                    'response.output_item.done',
                    'response.content_part.added',
                    'response.content_part.done',
                    'response.output_text.done',
                    'response.web_search_call.in_progress',
                    'response.web_search_call.searching',
                    'response.web_search_call.completed',
                    'response.file_search_call.in_progress',
                    'response.file_search_call.searching',
                    'response.file_search_call.completed',
                    'response.mcp_list_tools.in_progress',
                    'response.mcp_list_tools.completed',
                    'response.mcp_call.in_progress',
                    'response.mcp_call_arguments.delta',
                    'response.mcp_call_arguments.done',
                    'response.mcp_call.completed',
                ]:
                    # è¿™äº›äº‹ä»¶ä¸éœ€è¦è½¬æ¢ï¼Œä½†æˆ‘ä»¬éœ€è¦ç»§ç»­å¾ªç¯
                    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ—¥å¿—è®°å½•
                    logger.debug(f"æ”¶åˆ° Responses API äº‹ä»¶: {event_type}")
                    continue

                # æœªçŸ¥äº‹ä»¶ç±»å‹
                else:
                    logger.warning(f"æœªå¤„ç†çš„ Responses API äº‹ä»¶ç±»å‹: {event_type}")

        except Exception as e:
            logger.error(f"OpenAIæµå¼è°ƒç”¨å¤±è´¥: {str(e)}")
            yield {"error": str(e)}

    async def _openai_compatible_stream_completion(
        self,
        model: str,
        messages: List[Union[Dict[str, str], Any]],  # Support both dict and Pydantic objects
        api_key: str,
        thinking_mode: bool = False,
        reasoning_summaries: str = "auto",
        tools: List[Dict[str, Any]] = None,
        use_native_search: bool = None,
        base_url: str = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """OpenAIå…¼å®¹æµå¼å®Œæˆ"""
        try:
            # å¦‚æœæ²¡æœ‰æä¾›base_urlï¼Œä½¿ç”¨é»˜è®¤çš„OpenAI URL
            if not base_url:
                base_url = "https://api.openai.com/v1"
                
            client = openai.AsyncOpenAI(
                api_key=api_key,
                base_url=base_url,
                timeout=self.default_timeout
            )
            
            # è½¬æ¢æ¶ˆæ¯æ ¼å¼ - åªæ”¯æŒåŸºæœ¬çš„æ–‡æœ¬æ¶ˆæ¯æ ¼å¼
            converted_messages = []
            for msg in messages:
                role = self._get_message_attr(msg, "role")
                content = self._get_message_attr(msg, "content")
                converted_messages.append({"role": role, "content": content})
            
            # æµå¼å‚æ•°
            stream_params = {
                "model": model,
                "messages": converted_messages,
                "stream": True,
                "temperature": 0.7,
                "max_tokens": 4000
            }
            
            stream = await client.chat.completions.create(**stream_params)
            
            async for chunk in stream:
                yield chunk.model_dump()
                
        except Exception as e:
            logger.error(f"OpenAIå…¼å®¹æµå¼è°ƒç”¨å¤±è´¥: {str(e)}")
            yield {"error": str(e)}

    async def _anthropic_stream_completion(
        self,
        model: str,
        messages: List[Union[Dict[str, str], Any]],
        api_key: str,
        thinking_mode: bool = False,
        reasoning_summaries: str = "auto",
        tools: List[Dict[str, Any]] = None,
        use_native_search: bool = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """Anthropicæµå¼å®Œæˆï¼Œæ”¯æŒExtended Thinkingã€Visionã€Citationsç­‰åŠŸèƒ½"""
        try:
            client = anthropic.AsyncAnthropic(
                api_key=api_key,
                timeout=self.default_timeout
            )
            
            logger.info(f"å¼€å§‹Anthropicæµå¼è°ƒç”¨: {model}, æ‰©å±•æ€è€ƒæ¨¡å¼: {thinking_mode}")
            
            system_message = ""
            user_messages = []
            
            # è½¬æ¢æ¶ˆæ¯æ ¼å¼ä»¥æ”¯æŒå¤šåª’ä½“å†…å®¹
            for msg in messages:
                role = self._get_message_attr(msg, "role")
                content = self._get_message_attr(msg, "content")
                
                if role == "system":
                    system_message = content
                else:
                    # è½¬æ¢ä¸ºAnthropic Messages APIæ ¼å¼
                    converted_msg = self._convert_message_to_anthropic_format(msg)
                    user_messages.append(converted_msg)
            
            # æ„å»ºæµå¼è¯·æ±‚å‚æ•°
            stream_params = {
                "model": model,
                "max_tokens": 4000,
                "messages": user_messages,
                "temperature": 0.7
            }
            
            # æ·»åŠ systemæ¶ˆæ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            if system_message:
                stream_params["system"] = system_message
            
            # Extended Thinkingæ”¯æŒ
            if thinking_mode:
                stream_params["thinking"] = {
                    "type": "enabled",
                    "budget_tokens": 10000  # å›ºå®šå€¼
                }
                logger.info("å¯ç”¨Claudeæµå¼æ‰©å±•æ€è€ƒæ¨¡å¼ï¼Œbudget_tokens: 10000")
            
            # å·¥å…·é…ç½®ï¼ˆå¦‚æœæœ‰ï¼‰
            if tools:
                anthropic_tools = self._convert_tools_to_anthropic_format(tools)
                if anthropic_tools:
                    stream_params["tools"] = anthropic_tools
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†Files APIï¼Œå¦‚æœæ˜¯åˆ™æ·»åŠ betaså‚æ•°
            uses_files_api = self._check_uses_files_api(user_messages)
            if uses_files_api:
                stream_params["betas"] = ["files-api-2025-04-14"]
                logger.info("æµå¼è°ƒç”¨æ£€æµ‹åˆ°Files APIä½¿ç”¨ï¼Œå·²æ·»åŠ betaså‚æ•°")
            
            # åˆ›å»ºæµå¼å“åº”
            content_text = ""
            thinking_content = ""
            message_id = None
            current_citations = []
            
            # æ ¹æ®æ˜¯å¦ä½¿ç”¨Files APIé€‰æ‹©æ­£ç¡®çš„å®¢æˆ·ç«¯æ–¹æ³•
            stream_context = client.beta.messages.stream(**stream_params) if uses_files_api else client.messages.stream(**stream_params)
            
            async with stream_context as stream:
                async for event in stream:
                    try:
                        # æ ¹æ®äº‹ä»¶ç±»å‹å¤„ç†ä¸åŒçš„æµå¼æ•°æ®
                        if hasattr(event, 'type'):
                            if event.type == "message_start":
                                # æ¶ˆæ¯å¼€å§‹
                                if hasattr(event, 'message') and hasattr(event.message, 'id'):
                                    message_id = event.message.id
                                
                                # å‘é€åˆå§‹chunk
                                chunk = {
                                    "id": f"msg_{message_id or 'stream'}",
                                    "choices": [{
                                        "delta": {
                                            "role": "assistant",
                                            "content": ""
                                        },
                                        "index": 0,
                                        "finish_reason": None
                                    }]
                                }
                                yield chunk
                            
                            elif event.type == "content_block_start":
                                # å†…å®¹å—å¼€å§‹ - å¯èƒ½æ˜¯textæˆ–thinking
                                if hasattr(event, 'content_block'):
                                    block_type = getattr(event.content_block, 'type', 'text')
                                    if block_type == "thinking" and thinking_mode:
                                        logger.debug("å¼€å§‹æ¥æ”¶thinkingå†…å®¹")
                            
                            elif event.type == "content_block_delta":
                                # å†…å®¹å¢é‡
                                if hasattr(event, 'delta'):
                                    delta_type = getattr(event.delta, 'type', 'text_delta')
                                    
                                    if delta_type == "text_delta":
                                        # æ–‡æœ¬å¢é‡
                                        text_delta = getattr(event.delta, 'text', '')
                                        content_text += text_delta
                                        
                                        chunk = {
                                            "id": f"msg_{message_id or 'stream'}",
                                            "choices": [{
                                                "delta": {
                                                    "content": text_delta
                                                },
                                                "index": 0,
                                                "finish_reason": None
                                            }]
                                        }
                                        yield chunk
                                    
                                    elif delta_type == "thinking_delta" and thinking_mode:
                                        # æ€è€ƒå¢é‡
                                        thinking_delta = getattr(event.delta, 'content', '') or getattr(event.delta, 'thinking', '')
                                        thinking_content += thinking_delta
                                        
                                        # æ€è€ƒå†…å®¹ä½œä¸ºreasoningå­—æ®µå‘é€
                                        chunk = {
                                            "id": f"msg_{message_id or 'stream'}",
                                            "choices": [{
                                                "delta": {
                                                    "reasoning": thinking_delta
                                                },
                                                "index": 0,
                                                "finish_reason": None
                                            }]
                                        }
                                        yield chunk
                                    
                                    elif delta_type == "citations_delta":
                                        # Citationså¢é‡
                                        if hasattr(event.delta, 'citation'):
                                            citation = {
                                                "type": getattr(event.delta.citation, 'type', 'unknown'),
                                                "cited_text": getattr(event.delta.citation, 'cited_text', ''),
                                                "source": getattr(event.delta.citation, 'source', ''),
                                                "title": getattr(event.delta.citation, 'title', ''),
                                                "document_index": getattr(event.delta.citation, 'document_index', 0)
                                            }
                                            current_citations.append(citation)
                            
                            elif event.type == "message_delta":
                                # æ¶ˆæ¯çº§åˆ«çš„å¢é‡ï¼Œé€šå¸¸åŒ…å«åœæ­¢åŸå› 
                                if hasattr(event, 'delta') and hasattr(event.delta, 'stop_reason'):
                                    stop_reason = self._map_anthropic_stop_reason(event.delta.stop_reason)
                                    
                                    chunk = {
                                        "id": f"msg_{message_id or 'stream'}",
                                        "choices": [{
                                            "delta": {},
                                            "index": 0,
                                            "finish_reason": stop_reason
                                        }]
                                    }
                                    
                                    # å¦‚æœæœ‰citationsï¼Œåœ¨æœ€åçš„chunkä¸­åŒ…å«
                                    if current_citations:
                                        chunk["choices"][0]["delta"]["citations"] = current_citations
                                    
                                    yield chunk
                            
                            elif event.type == "message_stop":
                                # æ¶ˆæ¯ç»“æŸ
                                logger.info(f"Anthropicæµå¼è°ƒç”¨å®Œæˆï¼Œæ€»æ–‡æœ¬é•¿åº¦: {len(content_text)}, thinkingé•¿åº¦: {len(thinking_content)}")
                                break
                    
                    except Exception as e:
                        logger.error(f"å¤„ç†Anthropicæµå¼äº‹ä»¶æ—¶å‡ºé”™: {str(e)}")
                        continue
                        
        except anthropic.AuthenticationError as e:
            logger.error(f"Anthropicæµå¼è®¤è¯å¤±è´¥: {str(e)}")
            yield {"error": "Anthropic APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥æ‚¨çš„APIå¯†é’¥"}
        except anthropic.RateLimitError as e:
            logger.error(f"Anthropicæµå¼é€Ÿç‡é™åˆ¶: {str(e)}")
            yield {"error": "Anthropic APIè¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•"}
        except Exception as e:
            logger.error(f"Anthropicæµå¼è°ƒç”¨å¤±è´¥: {str(e)}")
            yield {"error": f"Anthropicæµå¼è°ƒç”¨å¤±è´¥: {str(e)}"}